---
title: "BSTS Selected Models"
author: "ags"
date: "2021-01-20"
output:
  html_document:
    code_folding: hide
    fig_height: 6
    fig_width: 8
    theme: spacelab
    toc: yes
    toc_depth: 6
    toc_float: yes
    number_sections: yes
---

```{=html}
<style type="text/css">
.tablelines table, .tablelines td, .tablelines th {
  border: 1px solid black;
  }
.centrado {
  text-align: center;
}
.table.center {
  margin-left:auto; 
  margin-right:auto;
}
.table_wrapper{
  display: block;
  overflow-x: auto;
  white-space: nowrap;
}
code.r{
  font-size: 8px;
}
body{ /* Normal  */
    text-align: justify;
}
.superbigimage{
  overflow-y:scroll;
  white-space: nowrap;
}
.superbigimage img{
  overflow-y: scroll;
  overflow-x: hidden;
}
p.comment {
  background-color: #FF7F79;
    padding: 10px;
  border: 1px solid black;
  margin-left: 25px;
  border-radius: 5px;
  font-style: italic;
}
</style>
```
```{=html}
<style>
  p.comment {
    background-color: #ff9a9a;
      padding: 10px;
    border: 1px solid red;
    margin-left: 25px;
    border-radius: 5px;
    font-style: italic;
  }

</style>
```
```{r setup0, include=T, message=F, warning=F}
rm(list=ls());gc()
unlink('Consolidacion_BDs_cache', recursive = TRUE)
unlink('Consolidacion_BDs_FINAL_cache', recursive = TRUE)
#load(url("https://drive.google.com/uc?export=download&id=1zLfLpJjGCfMSfwrtTnaOdBSgGg2ZCqjR"))
load(paste0(getwd(),"/","Procesos hasta 4_2.RData"))

#xaringan::inf_mr()

if(isTRUE(getOption('knitr.in.progress'))==T){
    clus_iter=30000
} else {
  input <- readline('¿Are you gonna run the dataset with the whole iterations? (Si/No): ')
  if(input=="Si"){
    clus_iter=30000
  } else {
    clus_iter=1000
  }
}
```

```{r setup, include=T, message=F, warning=F}
#arriba puse algunas opciones para que por defecto escondiera el código
#también cargue algunos estilo .css para que el texto me apareciera justificado, entre otras cosas.
local({r <- getOption("repos")
       r["CRAN"] <- "http://cran.r-project.org" 
       options(repos=r)
})

`%>%` <- magrittr::`%>%`
copy_names <- function(x,row.names=FALSE,col.names=TRUE,dec=",",...) {
  if(class(ungroup(x))[1]=="tbl_df"){
        if(options()$OutDec=="."){
            options(OutDec = dec)
            write.table(format(data.frame(x)),"clipboard",sep="\t",row.names=FALSE,col.names=col.names,...)
            options(OutDec = ".")
          return(x)
        } else {
            options(OutDec = ",")
            write.table(format(data.frame(x)),"clipboard",sep="\t",row.names=FALSE,col.names=col.names,...)
            options(OutDec = ",")
          return(x)    
        }
  } else {
        if(options()$OutDec=="."){
            options(OutDec = dec)
            write.table(format(x),"clipboard",sep="\t",row.names=FALSE,col.names=col.names,...)
            options(OutDec = ".")
          return(x)
        } else {
            options(OutDec = ",")
            write.table(format(x),"clipboard",sep="\t",row.names=FALSE,col.names=col.names,...)
            options(OutDec = ",")
          return(x)       
  }
 }
}  

unlink('Consolidacion_BDs_cache', recursive = TRUE)
if(!require(pacman)){install.packages("pacman")}

pacman::p_unlock(lib.loc = .libPaths()) #para no tener problemas reinstalando paquetes
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)
#dejo los paquetes estadísticos que voy a utilizar

if(!require(plotly)){install.packages("plotly")}
if(!require(lubridate)){install.packages("lubridate")}
if(!require(htmlwidgets)){install.packages("htmlwidgets")}
if(!require(tidyverse)){install.packages("tidyverse")}
if(!require(gganimate)){install.packages("gganimate")}
if(!require(readr)){install.packages("readr")}
if(!require(stringr)){install.packages("stringr")}
if(!require(data.table)){install.packages("data.table")}
if(!require(DT)){install.packages("DT")}
if(!require(ggplot2)){install.packages("ggplot2")}
if(!require(lattice)){install.packages("lattice")}
if(!require(forecast)){install.packages("forecast")}
if(!require(zoo)){install.packages("zoo")}
if(!require(panelView)){install.packages("panelView")}
if(!require(janitor)){install.packages("janitor")}
if(!require(rjson)){install.packages("rjson")}
if(!require(estimatr)){install.packages("estimatr")} 
if(!require(CausalImpact)){install.packages("CausalImpact")}
if(!require(textreg)){install.packages("textreg")}
if(!require(sjPlot)){install.packages("sjPlot")}
if(!require(foreign)){install.packages("foreign")}
if(!require(tsModel)){install.packages("tsModel")}
if(!require(lmtest)){install.packages("lmtest")}
if(!require(Epi)){install.packages("Epi")}
if(!require(splines)){install.packages("splines")}
if(!require(vcd)){install.packages("vcd")}
if(!require(astsa)){install.packages("astsa")}
if(!require(forecast)){install.packages("forecast")}
if(!require(MASS)){install.packages("MASS")}
if(!require(ggsci)){install.packages("ggsci")}
if(!require(Hmisc)){install.packages("Hmisc")}
if(!require(compareGroups)){install.packages("compareGroups")}
if(!require(dplyr)){install.packages("dplyr")}
if(!require(ggforce)){install.packages("ggforce")}
if(!require(imputeTS)){install.packages("imputeTS")}
if(!require(doParallel)){install.packages("doParallel")}
if(!require(SCtools)){install.packages("SCtools")}
if(!require(MSCMT)){install.packages("MSCMT")}
if(!require(ISOweek)){install.packages("ISOweek")}
if(!require(gridExtra)){install.packages("gridExtra")}
if(!require(cowplot)){install.packages("cowplot")}
if(!require(grid)){install.packages("grid")}
if(!require(devtools)){install.packages("devtools")}
if(!require(Statamarkdown)){devtools::install_github("hemken/Statamarkdown", quiet=T,  upgrade="never")}

# Calculate the number of cores
no_cores <- detectCores() - 1
cl<-makeCluster(no_cores)
registerDoParallel(cl)

Sys.setlocale(category = "LC_ALL", locale = "english")

#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:
#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:
#:#:#:#:#:#:#:#:#:#:#:PARA GENERAR MATRICES DE PREDICCION BSTS#:#:#:#:#:#:#:#:#:
#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:

GetPosteriorStateSamples <- function(bsts.model) {
  # Returns a matrix of simulated values from the marginal posterior
  # distribution for the sum of all state variables.
  #
  # Args:
  #   bsts.model: A fitted model returned by \code{bsts()}.
  #
  # Returns:
  #   matrix [number of post-burn-in MCMC samples] x [time points]
  
  # Get state contributions (e.g., 1000 samples x 2 states x 365 time pts),
  # discarding burn-in samples (=> 900 x 2 x 365)
  burn <- SuggestBurn(0.1, bsts.model)
  #assert_that(burn > 0)
  state.contributions <- bsts.model$state.contributions[-seq_len(burn), , ,
                                                        drop = FALSE]
  
  # Sum across states, call it 'state.samples' (=> 900 x 365)
  state.samples <- rowSums(aperm(state.contributions, c(1, 3, 2)), dims = 2)
  return(state.samples)
}
ComputeResponseTrajectories <- function(bsts.model) {
  # Generates trajectories of the response variable. A trajectory is a simulated
  # time series drawn from the posterior predictive distribution over the data.
  # This function differs from GetPosteriorStateSamples(). The latter returns
  # the posterior mean of the response. This function returns the actual value
  # (posterior mean + observation noise).
  #
  # Args:
  #   bsts.model: A model object as returned by \code{bsts()}.
  #
  # Returns:
  #   matrix [number of post-burn-in MCMC samples] x [time points]
  
  # Get posterior state samples
  state.samples <- GetPosteriorStateSamples(bsts.model)
  
  # Get observation noise standard deviation samples
  burn <- SuggestBurn(0.1, bsts.model)
  #assert_that(burn > 0)
  sigma.obs <- bsts.model$sigma.obs[-seq_len(burn)]  # e.g., 900
  
  # Sample from the posterior predictive density over data
  n.samples <- dim(state.samples)[1]  # e.g., 900 x 365
  obs.noise.samples <- matrix(rnorm(prod(dim(state.samples)), 0, sigma.obs),
                              nrow = n.samples)
  y.samples <- state.samples + obs.noise.samples
  return(y.samples)
}


#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:
#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:
aicbic_plm <- function(object, criterion) {
  
  
  # object is "plm", "panelmodel" 
  # Lets panel data has index :index = c("Country", "Time")
  
  sp = summary(object)
  
  if(class(object)[1]=="plm"){
    u.hat <- residuals(sp) # extract residuals
    df <- cbind(as.vector(u.hat), attr(u.hat, "index"))
    names(df) <- c("resid", "Country", "Time")
    c = length(levels(df$Country)) # extract country dimension 
    t = length(levels(df$Time)) # extract time dimension 
    np = length(sp$coefficients[,1]) # number of parameters
    n.N = nrow(sp$model) # number of data
    s.sq  <- log( (sum(u.hat^2)/(n.N))) # log sum of squares
    
    # effect = c("individual", "time", "twoways", "nested"),
    # model = c("within", "random", "ht", "between", "pooling", "fd")
    
    # I am making example only with some of the versions:
    
    if (sp$args$model == "within" & sp$args$effect == "individual"){
      n = c
      np = np+n+1 # update number of parameters
    }
    
    if (sp$args$model == "within" & sp$args$effect == "time"){
      T = t
      np = np+T+1 # update number of parameters
    }
    
    if (sp$args$model == "within" & sp$args$effect == "twoways"){
      n = c
      T = t
      np = np+n+T # update number of parameters
    }
    aic <- round(       2*np  +  n.N * (  log(2*pi) + s.sq  + 1 ),1)
    bic <- round(log(n.N)*np  +  n.N * (  log(2*pi) + s.sq  + 1 ),1)
    
    if(criterion=="AIC"){
      names(aic) = "AIC"
      return(aic)
    }
    if(criterion=="BIC"){
      names(bic) = "BIC"
      return(bic)
    }
  }
}
```

# Dataset Compile

```{r datasets_cons0, echo=T, cache= T, paged.print=TRUE, warning=F}
library(compareGroups)
#pvals <- compareGroups::getResults(table, "p.overall")
table2 <- compareGroups::compareGroups(did ~ cons_total+ cons_trauma+ cons_resp+ cons_circ+ hosp_total+ hosp_trauma+ hosp_resp+ hosp_circ+ rate+ rate_resp, #27
                       method = c(cons_total=2, cons_trauma=2, cons_resp=2, cons_circ=2,  hosp_total=2,
                                  hosp_resp=2, hosp_circ=2, hosp_trauma=2,rate=2, rate_resp=2),
                      data = data15a64_rn_ratio,
                      include.miss = T,
                      var.equal=T)
                      #,
                      #subset = age == "15-64")
#p.adjust(pvals, method = "BH")
restab <- createTable(table2, show.n = F, show.p.overall = F)
 compareGroups::export2md(restab, first.strip = T, show.all = T,hide.no = "no",header.labels = c(`0`= "Pre- Oct 18, 2020", `1`="Post Oct 18, 2020"), size=12,col.names= c("", "Previous to social
protests","During social protests"),format="html",position="center",caption= "Table 1. Median descriptive table of emergency department consultations and hospitalizations, pre and port Ocober’s 2019 social protests in Chile")%>%#,p.overall = "p-value"
  kableExtra::add_footnote(paste0("Note. Percentiles 25 and 75 in brackets."), notation = "none")%>%
  kableExtra::scroll_box(width = "100%", height = "375px")
```

# Bayesian Structural Time Series Models

The model of Bayesian Structural Time Series (BSTS) with Causal Impact Analysis contains a local level component (observation equation linking observed data to a state vector) and a seasonal component (state equation that describes how the state vector evolves over time). Also it can contain other predictor series. The method uses a Markov chain Monte Carlo (MCMC) sampling of the structural time series given the observed data and the priors. We run MCMC simulations with 10,000 draws.

<br>

Previously, we selected those specifications on time series that showed less cumulative errors for each outcome. Here, we defined the final models by controlling **only with circulatory system hospitalizations**. We discarded other covariates, because we suspected that respiratory hospitalizations or consultations, trauma hospitalizations or consultations, and total consultations or total hospitalizations (composed by respiratory and trauma) may also be affected by social protests. 

<br>

For all the models, we used the term `prior.level.sd` to .1 instead of the default .01, assuming an unstable dataset with high residual volatility, although may give rise to wide prediction intervals. 

<br>

```{r borrar_impact_model_anteriores, echo=T, cache= T, paged.print=TRUE, warning=F,eval=T}
rm(list=ls()[startsWith(ls(),"impact")])
rm(list=ls()[startsWith(ls(),"model")])
#We did not include time-varying regression coefficients, because this may leads to overspecification when used in combination with a time-varying local trend or level, in which case a static regression is safer.
```


## Trauma Consultations

<br>

The model that had lower cumulative errors assumed a Random-Walk model and a Studentized Distribution with control variables.

<br>

```{r bsts3d_trauma_cons, echo=T, cache= T, paged.print=TRUE, warning=F,eval=T}
#The response variable (i.e., the first column in data) may contain missing values (NA), but covariates (all other columns in data) may not. If one of your covariates contains missing values, consider imputing (i.e., estimating) the missing values; if this is not feasible, leave the regressor out.

# Model 2
ss2d <- list()
# Local trend, weekly-seasonal #https://qastack.mx/stats/209426/predictions-from-bsts-model-in-r-are-failing-completely - PUSE UN GENERALIZED LOCAL TREND
ss2d <- AddLocalLevel(ss2d, 
                      c(as.numeric(unlist(data15a64_rn_ratio[which(data15a64_rn_ratio$did==0),"cons_trauma"])), rep(NA,10))
                      ) #
# Add weekly seasonal
ss2d <- AddSeasonal(ss2d, 
                    c(as.numeric(unlist(data15a64_rn_ratio[which(data15a64_rn_ratio$did==0),"cons_trauma"])), rep(NA,10)),
                    nseasons=5, season.duration = 52) #weeks OJO, ESTOS NO SON WEEKS VERDADEROS. PORQUE TENGO MAS DE EUN AÑO
ss2d <- AddSeasonal(ss2d, 
                    c(as.numeric(unlist(data15a64_rn_ratio[which(data15a64_rn_ratio$did==0),"cons_trauma"])), rep(NA,10)), 
                    nseasons = 12, season.duration =4) #years
#ss2 <- AddAutoAr(ss2, y = data15a64_rn_causal$log_hosp_trauma, lags = 1) #NO PUEDO AREGAR AR1 CON POISSON
# For example, to add a day-of-week component to data with daily granularity, use model.args = list(nseasons = 7, season.duration = 1). To add a day-of-week component to data with hourly granularity, set model.args = list(nseasons = 7, season.duration = 24).
model2d1_cons_trauma <-  bsts(c(as.numeric(unlist(data15a64_rn_ratio[which(data15a64_rn_ratio$did==0),"cons_trauma"])), rep(NA,10)),
                   state.specification = ss2d,#A list with elements created by AddLocalLinearTrend, AddSeasonal, and similar functions for adding components of state. See the help page for state.specification.
               family ="student", #A Bayesian Analysis of Time-Series Event Count Data
               niter = clus_iter, 
              # burn = 500, #http://finzi.psych.upenn.edu/library/bsts/html/SuggestBurn.html Suggest the size of an MCMC burn in sample as a proportion of the total run.
               seed= 2125)

#,
#               dynamic.regression=T)
#plot(model2d1_cons_trauma, main = "Model of Trauma Consultations (Circulatory System Hospitalizations as Control Var)")
#plot(model2d1_cons_trauma, "components")

impact3d1_cons_trauma <- CausalImpact(bsts.model = model2d1_cons_trauma,model.args = list(prior.level.sd=.1, dynamic.regression=T),
                       post.period.response = as.numeric(unlist(data15a64_rn_ratio[which(data15a64_rn_ratio$did==1),"cons_trauma"])))
#plot(impact3d1_cons_trauma, "original") 

burn2d1 <- SuggestBurn(0.1, model2d1_cons_trauma)

#summary(impact3d1_cons_trauma)
#summary(impact3d1) 
##summary(impact3d1,"report")

#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:
model2d1_cons_trauma_resp_traj<-(ComputeResponseTrajectories(model2d1_cons_trauma))
#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:
```


```{r bsts3d_trauma_cons_plot, echo=T, cache= T, paged.print=TRUE, warning=F, eval= F, fig.align="center", fig.cap="Figure 3. Estimated  Trends of Trauma Consultations", fig.height=10}
plot(impact3d1_cons_trauma)+
  xlab("Date")+
  ylab("Consultations")+
  scale_x_continuous(breaks=(c(seq(1,nrow(data15a64_rn_ratio),12),262)),
                     labels=as.character(unlist(data15a64_rn_ratio[c(seq(1,nrow(data15a64_rn_ratio),12),262),"date"])))+
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=.5,size=11),
        plot.caption = element_text(hjust = 0, face= "italic",size=9))+
  labs(caption="Note. The first panel shows the data and a counterfactual prediction for the post-treatment period (Blue dashed line);\nThe second panel shows the difference between observed data and counterfactual predictions;\nThe third panel adds up the pointwise contributions from the second panel;\nBlue area= Prediction intervals.")
```

## Respiratory Consultations

<br>

The model that had lower cumulative errors assumed a Random-Walk model and a Studentized Distribution with control variables.

<br>

```{r bsts3d2_cons_resp, echo=T, cache= T, paged.print=TRUE, warning=F,eval=T}
#The response variable (i.e., the first column in data) may contain missing values (NA), but covariates (all other columns in data) may not. If one of your covariates contains missing values, consider imputing (i.e., estimating) the missing values; if this is not feasible, leave the regressor out.

# Model 2
ss2d <- list()
# Local trend, weekly-seasonal #https://qastack.mx/stats/209426/predictions-from-bsts-model-in-r-are-failing-completely - PUSE UN GENERALIZED LOCAL TREND
ss2d <- AddLocalLevel(ss2d,c(as.numeric(unlist(data15a64_rn_ratio[which(data15a64_rn_ratio$did==0),"cons_resp"])), rep(NA,10))
                      ) #
# Add weekly seasonal
ss2d <- AddSeasonal(ss2d, 
                    c(as.numeric(unlist(data15a64_rn_ratio[which(data15a64_rn_ratio$did==0),"cons_resp"])), rep(NA,10)), 
                    nseasons=5, season.duration = 52) #weeks OJO, ESTOS NO SON WEEKS VERDADEROS. PORQUE TENGO MAS DE EUN AÑO
ss2d <- AddSeasonal(ss2d, 
                    c(as.numeric(unlist(data15a64_rn_ratio[which(data15a64_rn_ratio$did==0),"cons_resp"])), rep(NA,10)), 
                    nseasons = 12, season.duration =4) #years
#ss2 <- AddAutoAr(ss2, y = data15a64_rn_causal$hosp_trauma, lags = 1) #NO PUEDO AREGAR AR1 CON POISSON
# For example, to add a day-of-week component to data with daily granularity, use model.args = list(nseasons = 7, season.duration = 1). To add a day-of-week component to data with hourly granularity, set model.args = list(nseasons = 7, season.duration = 24).

model2d_cons_resp <- bsts(c(as.numeric(unlist(data15a64_rn_ratio[which(data15a64_rn_ratio$did==0),"cons_resp"])), rep(NA,10)),
               state.specification = ss2d, #A list with elements created by AddLocalLinearTrend, AddSeasonal, and similar functions for adding components of state. See the help page for state.specification.
               family ="student", #A Bayesian Analysis of Time-Series Event Count Data
               niter = clus_iter, 
              # burn = 500, #http://finzi.psych.upenn.edu/library/bsts/html/SuggestBurn.html Suggest the size of an MCMC burn in sample as a proportion of the total run.
               model.options = BstsOptions(save.prediction.errors = TRUE),
               seed= 2125)
#,
#               dynamic.regression=T)
#plot(model2d_cons_resp, main = "Model 2")
#plot(model2d_cons_resp, "components")

impact3d_cons_resp <- CausalImpact(bsts.model = model2d_cons_resp,model.args = list(prior.level.sd=.1, dynamic.regression=T),
                       post.period.response = as.numeric(unlist(data15a64_rn_ratio[which(data15a64_rn_ratio$did==1),"cons_resp"])))
#plot(impact3d, "original") 

burn2d <- SuggestBurn(0.1, model2d_cons_resp)

#summary(impact3d_cons_resp)
```


## Trauma Hospitalizations

<br>

The model that had lower cumulative errors assumed a Random-Walk model and a Studentized Distribution with control variables.

<br>

```{r bsts3d2_trauma_hosp, echo=T, cache= T, paged.print=TRUE, warning=F,eval=T}
#The response variable (i.e., the first column in data) may contain missing values (NA), but covariates (all other columns in data) may not. If one of your covariates contains missing values, consider imputing (i.e., estimating) the missing values; if this is not feasible, leave the regressor out.

# Model 2
ss2d <- list()
# Local trend, weekly-seasonal #https://qastack.mx/stats/209426/predictions-from-bsts-model-in-r-are-failing-completely - PUSE UN GENERALIZED LOCAL TREND
ss2d <- AddLocalLevel(ss2d, c(as.numeric(unlist(data15a64_rn_ratio[which(data15a64_rn_ratio$did==0),"hosp_trauma"])), rep(NA,10))) #
# Add weekly seasonal
ss2d <- AddSeasonal(ss2d, c(as.numeric(unlist(data15a64_rn_ratio[which(data15a64_rn_ratio$did==0),"hosp_trauma"])), rep(NA,10)), nseasons=5, season.duration = 52) #weeks OJO, ESTOS NO SON WEEKS VERDADEROS. PORQUE TENGO MAS DE EUN AÑO
ss2d <- AddSeasonal(ss2d, c(as.numeric(unlist(data15a64_rn_ratio[which(data15a64_rn_ratio$did==0),"hosp_trauma"])), rep(NA,10)), 
                     nseasons = 12, season.duration =4) #years
#ss2 <- AddAutoAr(ss2, y = data15a64_rn_causal$log_hosp_trauma, lags = 1) #NO PUEDO AREGAR AR1 CON POISSON
# For example, to add a day-of-week component to data with daily granularity, use model.args = list(nseasons = 7, season.duration = 1). To add a day-of-week component to data with hourly granularity, set model.args = list(nseasons = 7, season.duration = 24).
model2d_trauma_hosp <- bsts(c(as.numeric(unlist(data15a64_rn_ratio[which(data15a64_rn_ratio$did==0),"hosp_trauma"])), rep(NA,10)),
                state.specification = ss2d,             
               family ="student", #A Bayesian Analysis of Time-Series Event Count Data
               niter = clus_iter, 
              # burn = 500, #http://finzi.psych.upenn.edu/library/bsts/html/SuggestBurn.html Suggest the size of an MCMC burn in sample as a proportion of the total run.
               seed= 2125)
#,
#               dynamic.regression=T)
#plot(model2d_trauma_hosp, main = "Model 2")
#plot(model2d_trauma_hosp, "components")

impact3d_hosp_trauma <- CausalImpact(bsts.model = model2d_trauma_hosp,model.args = list(prior.level.sd=.1, dynamic.regression=T), 
                       post.period.response =as.numeric(unlist(data15a64_rn_ratio[which(data15a64_rn_ratio$did==1),"hosp_trauma"])),
                        )
#plot(impact3d_hosp_trauma, "original") 

burn2d <- SuggestBurn(0.1, model2d_trauma_hosp)

#plot(impact3d)
#summary(impact3d_hosp_trauma) 
##summary(impact3d,"report")
#dynamic.regression Whether to include time-varying regression coefficients. In combination with a time-varying local trend or even a time-varying local level, this often leads to overspecification, in which case a static regression is safer. Defaults to FALSE.
#
#Prior standard deviation of the Gaussian random walk of the local level. Expressed in terms of data standard deviations. Defaults to 0.01, a typical choice for well-behaved and stable datasets with low residual volatility after regressing out known predictors (e.g., web searches or sales in high quantities). When in doubt, a safer option is to use 0.1, as validated on synthetic data, although this may sometimes give rise to unrealistically wide prediction intervals.
#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:
model2d_trauma_hosp_resp_traj<-(ComputeResponseTrajectories(model2d_trauma_hosp))
#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:
```

```{r bsts3d2_trauma_hosp_plot, echo=T, cache= T, paged.print=TRUE, warning=F, eval=F, fig.align="center", fig.cap="Figure 1. Estimated  Trends of Trauma Hospitalizations", fig.height=10}
plot(impact3d_hosp_trauma)+
  xlab("Date")+
  ylab("Hospitalizations")+
  scale_x_continuous(breaks=(c(seq(1,nrow(data15a64_rn_ratio),12),262)),
                     labels=as.character(unlist(data15a64_rn_ratio[c(seq(1,nrow(data15a64_rn_ratio),12),262),"date"])))+
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=.5,size=11),
        plot.caption = element_text(hjust = 0, face= "italic",size=9))+
  labs(caption="Note. The first panel shows the data and a counterfactual prediction for the post-treatment period (Blue dashed line);\nThe second panel shows the difference between observed data and counterfactual predictions;\nThe third panel adds up the pointwise contributions from the second panel;\nBlue area= Prediction intervals.")
```

## Respiratory Hospitalizations

<br>

The model that had lower cumulative errors assumed a Random-Walk model and a Studentized Distribution, but without control variables. We decided to include control variables in order to reflect most adequately the uniqueness of the impact of the social protests in respiratory hospitalizations.

<br>

```{r bsts3d_resp_hosp, echo=T, cache= T, paged.print=TRUE, warning=F,eval=T}
#The response variable (i.e., the first column in data) may contain missing values (NA), but covariates (all other columns in data) may not. If one of your covariates contains missing values, consider imputing (i.e., estimating) the missing values; if this is not feasible, leave the regressor out.

# Model 2
ss2d <- list()
# Local trend, weekly-seasonal #https://qastack.mx/stats/209426/predictions-from-bsts-model-in-r-are-failing-completely - PUSE UN GENERALIZED LOCAL TREND
ss2d <- AddLocalLevel(ss2d, c(as.numeric(unlist(data15a64_rn_ratio[which(data15a64_rn_ratio$did==0),"hosp_resp"])), rep(NA,10))
                      ) #
# Add weekly seasonal
ss2d <- AddSeasonal(ss2d, c(as.numeric(unlist(data15a64_rn_ratio[which(data15a64_rn_ratio$did==0),"hosp_resp"])), rep(NA,10)),
                    nseasons=5, season.duration = 52) #weeks OJO, ESTOS NO SON WEEKS VERDADEROS. PORQUE TENGO MAS DE EUN AÑO
ss2d <- AddSeasonal(ss2d, c(as.numeric(unlist(data15a64_rn_ratio[which(data15a64_rn_ratio$did==0),"hosp_resp"])), rep(NA,10)), 
                    nseasons = 12, season.duration =4) #years
#ss2 <- AddAutoAr(ss2, y = data15a64_rn_causal$hosp_trauma, lags = 1) #NO PUEDO AREGAR AR1 CON POISSON
# For example, to add a day-of-week component to data with daily granularity, use model.args = list(nseasons = 7, season.duration = 1). To add a day-of-week component to data with hourly granularity, set model.args = list(nseasons = 7, season.duration = 24).
model2d1_hosp_resp <- 
  bsts(c(as.numeric(unlist(data15a64_rn_ratio[which(data15a64_rn_ratio$did==0),"cons_trauma"])), rep(NA,10)),
               state.specification = ss2d, #A list with elements created by AddLocalLinearTrend, AddSeasonal, and similar functions for adding components of state. See the help page for state.specification.
               family ="student", #A Bayesian Analysis of Time-Series Event Count Data
               niter = clus_iter,
              # burn = 500, #http://finzi.psych.upenn.edu/library/bsts/html/SuggestBurn.html Suggest the size of an MCMC burn in sample as a proportion of the total run.
               seed= 2125)
#,
#               dynamic.regression=T)
#plot(model2d1_hosp_resp, main = "Model of Respiratory Hospitalizations (Circulatory System Hospitalizations as Control Var)")
#plot(model2d1_hosp_resp, "components")

impact3d1_hosp_resp <- CausalImpact(bsts.model = model2d1_hosp_resp,model.args = list(prior.level.sd=.1, dynamic.regression=T),
                       post.period.response = as.numeric(unlist(data15a64_rn_ratio[which(data15a64_rn_ratio$did==1),"hosp_resp"]))
                         )
#plot(impact3d1_hosp_resp, "original") 

burn2d1 <- SuggestBurn(0.1, model2d1_hosp_resp)

#summary(impact3d1_hosp_resp) 
##summary(impact3d1,"report")
```

```{r bsts3d_resp_hosp_plot, echo=T, cache= T, paged.print=TRUE, warning=F, eval=F, fig.align="center", fig.cap="Figure 2. Estimated  Trends of Respiratory Hospitalizations", fig.height=10}
plot(impact3d1_hosp_resp)+
  xlab("Date")+
  ylab("Hospitalizations")+
  scale_x_continuous(breaks=(c(seq(1,nrow(data15a64_rn_ratio),12),262)),
                     labels=as.character(unlist(data15a64_rn_ratio[c(seq(1,nrow(data15a64_rn_ratio),12),262),"date"])))+
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=.5,size=11),
        plot.caption = element_text(hjust = 0, face= "italic",size=9))+
  labs(caption="Note. The first panel shows the data and a counterfactual prediction for the post-treatment period (Blue dashed line);\nThe second panel shows the difference between observed data and counterfactual predictions;\nThe third panel adds up the pointwise contributions from the second panel;\nBlue area= Prediction intervals.")
```

```{r bsts3d2_cons_resp_plot, echo=T, cache= T, paged.print=TRUE, warning=F, eval=F, fig.align="center", fig.cap="Figure 4. Estimated Trends of Respiratory Consultations", fig.height=10}
plot(impact3d_cons_resp)+
  xlab("Date")+
  ylab("Consultations")+
  scale_x_continuous(breaks=(c(seq(1,nrow(data15a64_rn_ratio),12),262)),
                     labels=as.character(unlist(data15a64_rn_ratio[c(seq(1,nrow(data15a64_rn_ratio),12),262),"date"])))+
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=.5,size=11),
        plot.caption = element_text(hjust = 0, face= "italic",size=9))+
  labs(caption="Note. The first panel shows the data and a counterfactual prediction for the post-treatment period (Blue dashed line);\nThe second panel shows the difference between observed data and counterfactual predictions;\nThe third panel adds up the pointwise contributions from the second panel;\nBlue area= Prediction intervals.")
```

## Trauma Hospitalizations per 1,000 consultations

```{r fig1_plot_ratio_cnts, echo=T, cache= T, paged.print=TRUE, warning=F, eval=F, fig.align="center", fig.cap="Figure 1. Yearly Rate of Trauma Hospitalizations", fig.height=12}
#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_
<br>

We generated a plot of the series of the rate of hospitalizations per trauma consultations per 1,000 consultations in each year.

<br>
#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_
ratio_plot<-
data15a64_rn_ratio %>% 
  dplyr::select(1:4,isoweek,rate,rate_resp,rate_circ) %>% 
  pivot_longer(cols=c("rate","rate_resp","rate_circ"), names_to = "variable", values_to = "rate") %>% 
  dplyr::arrange(year_week) %>% 
  dplyr::mutate(variable=dplyr::case_when(variable=="rate"~"Trauma",
                                          variable=="rate_resp"~"Respiratory",
                                          variable=="rate_circ"~"Circulatory")) %>% 
  dplyr::mutate(label_text=paste0("<br>Date: ",year_week,"<br>Rate: ",round(rate,0),"<br>Outcome: ",variable)) %>% 
   ggplot() + #median
  facet_wrap(.~year, ncol = 1,strip.position="right") + 
  geom_line(aes(x=isoweek, y =rate, group=variable, color=variable, label= label_text)) + 
  #geom_point(aes(x=fech_week, y =count, group=variable, color=variable,shape=variable),size=1) + 
  #geom_jitter(aes(y = hosp_trauma,x = isoweek, color = year),width = 0.5, alpha = 0.3)+
  guides(color=F)+
  theme_bw() + 
  theme(strip.background  = element_blank(),
        strip.text = element_text(face="bold", size=7))+
  ylab("") + 
  theme(strip.text.x = element_text(size = 8, face = "bold"),
        legend.position = "bottom",
        plot.caption=element_text(hjust = 0),
        strip.background  = element_blank())+
  xlab("Week")+
  scale_x_continuous(
    breaks = seq(from = 1, to = 52, by =4),
    labels = seq(from = 1, to = 52, by =4),#,
    #  label = c("two", "four", "six")
  )
#+
#  scale_y_continuous(limits=c(0,.25),labels = scales::percent)
ggplotly(ratio_plot, tooltip="label_text") %>% 
  layout(showlegend = F)
```

<br>

The model chosen assumed a Random-Walk model and a Studentized Distribution with control variables. We selected this model because both outcomes showed less cumulative errors assuming this structure.

<br>

```{r bsts_ratio, echo=T, cache= T, paged.print=TRUE, warning=F,eval=T}
#https://github.com/google/CausalImpact/tree/master/R

# Model 2
ss2d <- list()
# Local trend, weekly-seasonal #https://qastack.mx/stats/209426/predictions-from-bsts-model-in-r-are-failing-completely - PUSE UN GENERALIZED LOCAL TREND
ss2d <- AddLocalLevel(ss2d,c(as.numeric(unlist(data15a64_rn_ratio[which(data15a64_rn_ratio$did==0),"rate"])), rep(NA,10))
                      ) #
# Add weekly seasonal
ss2d <- AddSeasonal(ss2d, 
                    c(as.numeric(unlist(data15a64_rn_ratio[which(data15a64_rn_ratio$did==0),"rate"])), rep(NA,10)), 
                    nseasons=5, season.duration = 52) #weeks OJO, ESTOS NO SON WEEKS VERDADEROS. PORQUE TENGO MAS DE EUN AÑO
ss2d <- AddSeasonal(ss2d, 
                    c(as.numeric(unlist(data15a64_rn_ratio[which(data15a64_rn_ratio$did==0),"rate"])), rep(NA,10)), 
                    nseasons = 12, season.duration =4) #years
#ss2 <- AddAutoAr(ss2, y = data15a64_rn_causal$hosp_trauma, lags = 1) #NO PUEDO AREGAR AR1 CON POISSON
# For example, to add a day-of-week component to data with daily granularity, use model.args = list(nseasons = 7, season.duration = 1). To add a day-of-week component to data with hourly granularity, set model.args = list(nseasons = 7, season.duration = 24).

model2d_ratio <- bsts(c(as.numeric(unlist(data15a64_rn_ratio[which(data15a64_rn_ratio$did==0),"rate"])), rep(NA,10)) ~
                   as.numeric(unlist(data15a64_rn_ratio[,"rate_circ"]))                   ,
               state.specification = ss2d, #A list with elements created by AddLocalLinearTrend, AddSeasonal, and similar functions for adding components of state. See the help page for state.specification.
               family ="student", #A Bayesian Analysis of Time-Series Event Count Data
               niter = clus_iter, 
              # burn = 500, #http://finzi.psych.upenn.edu/library/bsts/html/SuggestBurn.html Suggest the size of an MCMC burn in sample as a proportion of the total run.
               seed= 2125)
#,
#              
#plot(model2d_cons_resp, main = "Model 2")
#plot(model2d_cons_resp, "components")

impact3d_ratio <- CausalImpact(bsts.model = model2d_ratio,model.args = list(prior.level.sd=.1, dynamic.regression=T),
              post.period.response = as.numeric(unlist(data15a64_rn_ratio[which(data15a64_rn_ratio$did==1),"rate"])))
#plot(impact3d, "original") 

burn2d <- SuggestBurn(0.1, model2d_ratio)

#summary(impact3d_ratio)
```

```{r plot_bsts_ratio, echo=T, cache= T, paged.print=TRUE, warning=F, eval=F, fig.align="center", fig.cap="Figure 7. Estimated Trends of the Rate of Trauma Hospitalizations per Trauma Consultations per 1,000 population", fig.height=10}
plot(impact3d_ratio)+
  xlab("Date")+
  ylab("Ratio")+
  scale_x_continuous(breaks=(c(seq(1,nrow(data15a64_rn),12),262)),
                     labels=as.character(unlist(data15a64_rn[c(seq(1,nrow(data15a64_rn),12),262),"date"])))+
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=.5,size=11),
        plot.caption = element_text(hjust = 0, face= "italic",size=9))+
  #scale_y_continuous(labels=scales::percent)+
  labs(caption="Note. The first panel shows the data and a counterfactual prediction for the post-treatment period (Blue dashed line);\nThe second panel shows the difference between observed data and counterfactual predictions;\nThe third panel adds up the pointwise contributions from the second panel;\nBlue area= Prediction intervals.")
```


```{r plot_fitted_vs_actual_mcmc, echo=T, cache= T, paged.print=TRUE, warning=F, eval=F, fig.align='center', fig.cap= "Figure 8. Actual linear trend vs. Fitted Line, Rate of Trauma Hospitalizations",fig.height=12}
<br>

We additionally looked over the matrix of MCMC draws and compared the trajectories generated in the trauma consultations and trauma hospitalizations.

<br>
#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_
#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_
#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_
#RESPONSE TRAJECTORIES EJE- X (time), EJE-Y (mcmc.iteration)

#c(as.character(unlist(data15a64_rn[which(data15a64_rn$did==0),"date"])), rep(NA,10))
#c(as.character(unlist(data15a64_rn[,"date"])))
model2d_cons_trauma_resp_traj<-ComputeResponseTrajectories(model2d1_cons_trauma)
model2d_trauma_hosp_resp_traj<-ComputeResponseTrajectories(model2d_trauma_hosp)
model2d_prop_trauma_resp_traj<- (model2d_trauma_hosp_resp_traj/model2d_cons_trauma_resp_traj)*1000

model2d_cons_trauma_resp_traj_df<-data.frame(model2d_cons_trauma_resp_traj)
model2d_trauma_hosp_resp_traj_df<-data.frame(model2d_trauma_hosp_resp_traj)
model2d_prop_trauma_resp_traj_df<-data.frame(model2d_prop_trauma_resp_traj)

colnames(model2d_cons_trauma_resp_traj_df) <- as.character(unlist(data15a64_rn[,"date"]))
colnames(model2d_trauma_hosp_resp_traj_df) <- as.character(unlist(data15a64_rn[,"date"]))
colnames(model2d_prop_trauma_resp_traj_df) <- as.character(unlist(data15a64_rn[,"date"]))

model2d_trauma_hosp_resp_traj_df_melt<-
  model2d_trauma_hosp_resp_traj_df %>% 
      dplyr::mutate(mcmc_sample=row_number()) %>% 
      dplyr::select(mcmc_sample,everything()) %>% 
      melt(id.vars ="mcmc_sample") %>% 
      rename("date"="variable")
model2d_trauma_cons_resp_resp_traj_df_melt<-
  model2d_cons_trauma_resp_traj_df %>% 
      dplyr::mutate(mcmc_sample=row_number()) %>% 
      dplyr::select(mcmc_sample,everything()) %>% 
      melt(id.vars ="mcmc_sample") %>% 
      rename("date"="variable")
model2d_prop_trauma_resp_traj_df_melt<-
  model2d_prop_trauma_resp_traj_df %>% 
      dplyr::mutate(mcmc_sample=row_number()) %>% 
      dplyr::select(mcmc_sample,everything()) %>% 
      melt(id.vars ="mcmc_sample") %>% 
      rename("date"="variable")

model2d_rate_trauma_hosp_cons_resp_traj_df_melt<-
  model2d_trauma_hosp_resp_traj_df_melt %>% 
  dplyr::rename("trauma_hosp"="value") %>% 
  dplyr::left_join(model2d_trauma_cons_resp_resp_traj_df_melt,by = c("mcmc_sample", "date")) %>% 
  dplyr::rename("trauma_cons"="value") %>% 
  dplyr::mutate(rate_trauma=(trauma_hosp/trauma_cons)*1000)

model2d_rate_trauma_resp_traj_df_melt_final<-
model2d_rate_trauma_hosp_cons_resp_traj_df_melt %>% 
     dplyr::mutate(date=as.Date(date)) %>% 
     # dplyr::filter(date>="2019-10-21") %>% 
     dplyr::group_by(date) %>% 
    dplyr::summarise(mean = mean(rate_trauma),
                      q025 = quantile(rate_trauma, .025),
                      q975 = quantile(rate_trauma, .975),
                      n=n()) %>%
     ungroup()
#model2d_prop_trauma_resp_traj_df_melt_post<-
#    model2d_prop_trauma_hosp_cons_resp_traj_df_melt %>% 
#      dplyr::mutate(date=as.Date(date)) %>% 
#     # dplyr::filter(date>="2019-10-21") %>% 
#  dplyr::group_by(date) %>% 
#  dplyr::summarise(mean = mean(value, na.rm = TRUE),
#            sd = sd(value, na.rm = TRUE),
#            n = n()) %>%
#  dplyr::mutate(se = sd / sqrt(n),
#         lo_ci = mean - qt(1 - (0.05 / 2), n - 1) * se,
#         up_ci = mean +  (1 - (0.05 / 2), n - 1) * se) %>% 
#  ungroup()

#:#:#:#::#:PLOT#:#:#:#:#:#:
plot_comp_fit_actual_ratio<-
cbind.data.frame(model2d_rate_trauma_resp_traj_df_melt_final,
                 actual=as.numeric(unlist(data15a64_rn_ratio[,"rate"]))) %>% 
    ggplot(aes(x=date))+
      geom_line(aes(y=mean), size=1, color="darkblue") +
      geom_line(aes(y=actual), size=1, color="black")+
  #geom_ribbon(aes(x=date, y=mean, ymin = lo_ci, ymax = up_ci), fill = "grey70")+
  geom_ribbon(aes(ymin=q025,ymax=q975),fill="steelblue", alpha = 0.35)+
  theme_sjplot()+
  ylab("Rate of Hospitalizations per Consultations per 1,000 population")+
  xlab("Date")+
   theme(strip.text.x = element_text(size = 8, face = "bold"),
        legend.position = "bottom",
        plot.caption=element_text(hjust = 0),
        strip.background  = element_blank(),
        axis.text.x=element_text(angle = -90, hjust = 0),
        legend.title = element_blank())
  #scale_y_continuous(labels = scales::percent)
   # scale_x_date(labels = scales::date_format("%Y-%m"),
  #             limits = c(as.Date("2015-01-01"),as.Date("2019-12-31")),
  #               breaks = "3 months")
  #facet_zoom(xlim = c(253, nrow(actual_vs_fitted_and_forecast_arima)))
plot_comp_fit_actual_ratio+
    ggforce::facet_zoom(x = date>=as.Date("2019-10-01") & date<=as.Date("2019-12-31"),shrink=F,zoom.size = .5)+
    geom_vline(xintercept = as.Date("2019-10-21"), col = 2, lty = 2, size=1)+
  labs(caption="Note. Vertical Line, Social Protests;\nBlack Line= Actual Trend; Blue Line= Average Estimations")

#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_
```

## Respiratory Hospitalizations per 1,000 consultations

<br>

The model chosen assumed a Random-Walk model and a Studentized Distribution with control variables. We selected this model because both outcomes showed less cumulative errors assuming this structure.

<br>

```{r bsts_ratio_resp, echo=T, cache= T, paged.print=TRUE, warning=F,eval=T}
#https://github.com/google/CausalImpact/tree/master/R

# Model 2
ss2d <- list()
# Local trend, weekly-seasonal #https://qastack.mx/stats/209426/predictions-from-bsts-model-in-r-are-failing-completely - PUSE UN GENERALIZED LOCAL TREND
ss2d <- AddLocalLevel(ss2d,c(as.numeric(unlist(data15a64_rn_ratio[which(data15a64_rn_ratio$did==0),"rate_resp"])), rep(NA,10))
                      ) #
# Add weekly seasonal
ss2d <- AddSeasonal(ss2d, 
                    c(as.numeric(unlist(data15a64_rn_ratio[which(data15a64_rn_ratio$did==0),"rate_resp"])), rep(NA,10)), 
                    nseasons=5, season.duration = 52) #weeks OJO, ESTOS NO SON WEEKS VERDADEROS. PORQUE TENGO MAS DE EUN AÑO
ss2d <- AddSeasonal(ss2d, 
                    c(as.numeric(unlist(data15a64_rn_ratio[which(data15a64_rn_ratio$did==0),"rate_resp"])), rep(NA,10)), 
                    nseasons = 12, season.duration =4) #years
#ss2 <- AddAutoAr(ss2, y = data15a64_rn_causal$hosp_trauma, lags = 1) #NO PUEDO AREGAR AR1 CON POISSON
# For example, to add a day-of-week component to data with daily granularity, use model.args = list(nseasons = 7, season.duration = 1). To add a day-of-week component to data with hourly granularity, set model.args = list(nseasons = 7, season.duration = 24).

model2d_ratio_resp <- bsts(c(as.numeric(unlist(data15a64_rn_ratio[which(data15a64_rn_ratio$did==0),"rate_resp"])), rep(NA,10)) ~
                   as.numeric(unlist(data15a64_rn_ratio[,"rate_circ"]))                   ,
               state.specification = ss2d, #A list with elements created by AddLocalLinearTrend, AddSeasonal, and similar functions for adding components of state. See the help page for state.specification.
               family ="student", #A Bayesian Analysis of Time-Series Event Count Data
               niter = clus_iter, 
              # burn = 500, #http://finzi.psych.upenn.edu/library/bsts/html/SuggestBurn.html Suggest the size of an MCMC burn in sample as a proportion of the total run.
               seed= 2125)
#,
#              
#plot(model2d_cons_resp, main = "Model 2")
#plot(model2d_cons_resp, "components")

impact3d_ratio_resp <- CausalImpact(bsts.model = model2d_ratio_resp,model.args = list(prior.level.sd=.1, dynamic.regression=T),
              post.period.response = as.numeric(unlist(data15a64_rn_ratio[which(data15a64_rn_ratio$did==1),"rate_resp"])))
#plot(impact3d, "original") 

burn2d <- SuggestBurn(0.1, model2d_ratio_resp)

#summary(model2d_ratio_resp)
```

```{r plot_bsts_ratio_resp, echo=T, cache= T, paged.print=TRUE, warning=F, eval=F, fig.align="center", fig.cap="Figure 9. Estimated Trends of the Rate of Respiratory Hospitalizations per Respiratory Consultations per 1,000 population", fig.height=10}
plot(impact3d_ratio_resp)+
  xlab("Date")+
  ylab("Ratio")+
  scale_x_continuous(breaks=(c(seq(1,nrow(data15a64_rn),12),262)),
                     labels=as.character(unlist(data15a64_rn[c(seq(1,nrow(data15a64_rn),12),262),"date"])))+
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=.5,size=11),
        plot.caption = element_text(hjust = 0, face= "italic",size=9))+
  #scale_y_continuous(labels=scales::percent)+
  labs(caption="Note. The first panel shows the data and a counterfactual prediction for the post-treatment period (Blue dashed line);\nThe second panel shows the difference between observed data and counterfactual predictions;\nThe third panel adds up the pointwise contributions from the second panel;\nBlue area= Prediction intervals.")
```




```{r plot_fitted_vs_actual_mcmc_resp, echo=T, cache= T, paged.print=TRUE, warning=F, eval=F, fig.align='center', fig.cap= "Figure 10. Actual linear trend vs. Fitted Line, Rate of Respiratory Hospitalizations",fig.height=12}

<br>

We additionally looked over the matrix of MCMC draws and compared the trajectories generated in the trauma consultations and trauma hospitalizations.

<br>
#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_
#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_
#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_
#RESPONSE TRAJECTORIES EJE- X (time), EJE-Y (mcmc.iteration)

#c(as.character(unlist(data15a64_rn[which(data15a64_rn$did==0),"date"])), rep(NA,10))
#c(as.character(unlist(data15a64_rn[,"date"])))
model2d_resp_cons_resp_traj<-ComputeResponseTrajectories(model2d_cons_resp)
model2d_resp_hosp_resp_traj<-ComputeResponseTrajectories(model2d1_hosp_resp)
model2d_prop_resp_resp_traj<- (model2d_resp_hosp_resp_traj/model2d_resp_cons_resp_traj)*1000

model2d_resp_cons_resp_traj_df<-data.frame(model2d_resp_cons_resp_traj)
model2d_resp_hosp_resp_traj_df<-data.frame(model2d_resp_hosp_resp_traj)
model2d_prop_resp_resp_traj_df<-data.frame(model2d_prop_resp_resp_traj)

colnames(model2d_resp_cons_resp_traj_df) <- as.character(unlist(data15a64_rn[,"date"]))
colnames(model2d_resp_hosp_resp_traj_df) <- as.character(unlist(data15a64_rn[,"date"]))
colnames(model2d_prop_resp_resp_traj_df) <- as.character(unlist(data15a64_rn[,"date"]))

model2d_resp_hosp_resp_traj_df_melt<-
  model2d_resp_hosp_resp_traj_df %>% 
      dplyr::mutate(mcmc_sample=row_number()) %>% 
      dplyr::select(mcmc_sample,everything()) %>% 
      melt(id.vars ="mcmc_sample") %>% 
      rename("date"="variable")
model2d_resp_cons_resp_traj_df_melt<-
  model2d_resp_cons_resp_traj_df %>% 
      dplyr::mutate(mcmc_sample=row_number()) %>% 
      dplyr::select(mcmc_sample,everything()) %>% 
      melt(id.vars ="mcmc_sample") %>% 
      rename("date"="variable")
model2d_prop_resp_resp_traj_df_melt<-
  model2d_prop_resp_resp_traj_df %>% 
      dplyr::mutate(mcmc_sample=row_number()) %>% 
      dplyr::select(mcmc_sample,everything()) %>% 
      melt(id.vars ="mcmc_sample") %>% 
      rename("date"="variable")

model2d_rate_resp_hosp_resp_traj_df_melt<-
  model2d_resp_hosp_resp_traj_df_melt %>% 
  dplyr::rename("resp_hosp"="value") %>% 
  dplyr::left_join(model2d_resp_cons_resp_traj_df_melt,by = c("mcmc_sample", "date")) %>% 
  dplyr::rename("resp_cons"="value") %>% 
  dplyr::mutate(rate_resp=(resp_hosp/resp_cons)*1000)

model2d_rate_resp_traj_df_melt_final<-
model2d_rate_resp_hosp_resp_traj_df_melt %>% 
     dplyr::mutate(date=as.Date(date)) %>% 
     # dplyr::filter(date>="2019-10-21") %>% 
     dplyr::group_by(date) %>% 
    dplyr::summarise(mean = mean(rate_resp),
                      q025 = quantile(rate_resp, .025),
                      q975 = quantile(rate_resp, .975),
                      n=n()) %>%
     ungroup()
#model2d_prop_trauma_resp_traj_df_melt_post<-
#    model2d_prop_trauma_hosp_cons_resp_traj_df_melt %>% 
#      dplyr::mutate(date=as.Date(date)) %>% 
#     # dplyr::filter(date>="2019-10-21") %>% 
#  dplyr::group_by(date) %>% 
#  dplyr::summarise(mean = mean(value, na.rm = TRUE),
#            sd = sd(value, na.rm = TRUE),
#            n = n()) %>%
#  dplyr::mutate(se = sd / sqrt(n),
#         lo_ci = mean - qt(1 - (0.05 / 2), n - 1) * se,
#         up_ci = mean +  (1 - (0.05 / 2), n - 1) * se) %>% 
#  ungroup()

#:#:#:#::#:PLOT#:#:#:#:#:#:
plot_comp_fit_actual_ratio<-
cbind.data.frame(model2d_rate_resp_traj_df_melt_final,
                 actual=as.numeric(unlist(data15a64_rn_ratio[,"rate_resp"]))) %>% 
    ggplot(aes(x=date))+
      geom_line(aes(y=mean), size=1, color="darkblue") +
      geom_line(aes(y=actual), size=1, color="black")+
  #geom_ribbon(aes(x=date, y=mean, ymin = lo_ci, ymax = up_ci), fill = "grey70")+
  geom_ribbon(aes(ymin=q025,ymax=q975),fill="steelblue", alpha = 0.35)+
  theme_sjplot()+
  ylab("Rate of Hospitalizations per Consultations per 1,000 population")+
  xlab("Date")+
   theme(strip.text.x = element_text(size = 8, face = "bold"),
        legend.position = "bottom",
        plot.caption=element_text(hjust = 0),
        strip.background  = element_blank(),
        axis.text.x=element_text(angle = -90, hjust = 0),
        legend.title = element_blank())
  #scale_y_continuous(labels = scales::percent)
   # scale_x_date(labels = scales::date_format("%Y-%m"),
  #             limits = c(as.Date("2015-01-01"),as.Date("2019-12-31")),
  #               breaks = "3 months")
  #facet_zoom(xlim = c(253, nrow(actual_vs_fitted_and_forecast_arima)))
plot_comp_fit_actual_ratio+
    ggforce::facet_zoom(x = date>=as.Date("2019-10-01") & date<=as.Date("2019-12-31"),shrink=F,zoom.size = .5)+
    geom_vline(xintercept = as.Date("2019-10-21"), col = 2, lty = 2, size=1)+
  labs(caption="Note. Vertical Line, Social Protests;\nBlack Line= Actual Trend; Blue Line= Average Estimations")
#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_
```

```{r BSTS_table, messages=T, eval=T, warnings=T}
vector_bsts_models<-c("impact3d1_cons_trauma", "impact3d_cons_resp","impact3d_hosp_trauma", "impact3d1_hosp_resp", "impact3d_ratio", "impact3d_ratio_resp")
names_outcomes<-c("Trauma Consultations","Respiratory Consultations","Trauma Hospitalizations","Respiratory Hospitalizations","Trauma Hospitalizations per 1,000 consultations","Respiratory Hospitalizations per 1,000 consultations")
df_results_bsts<-data.frame()
for (i in 1:6) {
  x<-vector_bsts_models[i]
dt_bsts<-cbind(
  outcome=names_outcomes[i],
  AE=sprintf("%4.2f",round(get(x)$summary$AbsEffect[1],2)),
  IC95_AE=paste0(sprintf("%4.2f",round(get(x)$summary$AbsEffect.lower[1],2)),", ",sprintf("%4.2f",round(get(x)$summary$AbsEffect.upper[1],2))),
  p=sprintf("%5.3f",round(get(x)$summary$p[1],5)),
  RE=sprintf("%4.2f",round(get(x)$summary$RelEffect[1]*100,2)),
  IC95_RE=paste0(sprintf("%4.2f",round(get(x)$summary$RelEffect.lower[1]*100,2)),", ",sprintf("%4.2f",round(get(x)$summary$RelEffect.upper[1]*100,2)))
  )
  df_results_bsts<-rbind.data.frame(df_results_bsts,dt_bsts)
}
df_results_bsts[which(df_results_bsts$p=="0.000"),"p"]<-"<0.001"

df_results_bsts %>% 
      knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
               caption = paste0("Table 2. Estimated effects of October’s 2019 social protests on the outcomes of interest"),
               col.names = c("Outcome of Interest","Average
Effect","95%Credible Interval", "P- Value","Relative Effect(%)","95%Credible Interval"),
               align =rep('c', 101)) %>%
    kableExtra::kable_styling(bootstrap_options = c("striped", "hover"),font_size= 11) %>% 
  kableExtra::add_footnote(c("a- Each model had a structure of studentized distribution of errors, and a conservative prior standard deviation of .1","b- Models also included circulatory hospitalizations as a control variable.","c- Models also included circulatory consultations as a control variable.", "d- Models also included the proportion of circulatory hospitalizations of circulatory consultations (x 1,000 population) as a control variable."),
                             notation = "none")%>%
  kableExtra::scroll_box(width = "100%", height = "375px")
```

<br>

```{r 10_prepare_data, messages=T, eval=T, warnings=T}

data15a64_rn_ratio_its<-
data15a64_rn_ratio %>% 
  dplyr::filter(isoweek!=53) %>% 
  dplyr::mutate(did=factor(did))

data15a64_rn_ratio_its_trauma_hosp<-
        cbind.data.frame(
        data15a64_rn_ratio_its[which(data15a64_rn_ratio_its$year==2015),"hosp_trauma"],
        data15a64_rn_ratio_its[which(data15a64_rn_ratio_its$year==2016),"hosp_trauma"],
        data15a64_rn_ratio_its[which(data15a64_rn_ratio_its$year==2017),"hosp_trauma"],
        data15a64_rn_ratio_its[which(data15a64_rn_ratio_its$year==2018),"hosp_trauma"],
        data15a64_rn_ratio_its[which(data15a64_rn_ratio_its$year==2019),"hosp_trauma"],
        data15a64_rn_ratio_its[which(data15a64_rn_ratio_its$year==2019),"did"],
        data15a64_rn_ratio_its[which(data15a64_rn_ratio_its$year==2019),"isoweek"]
        )
colnames(data15a64_rn_ratio_its_trauma_hosp)<- c("ht_2015","ht_2016","ht_2017","ht_2018","ht_2019","did","isoweek")


data15a64_rn_ratio_its_resp_hosp<-
        cbind.data.frame(
        data15a64_rn_ratio_its[which(data15a64_rn_ratio_its$year==2015),"hosp_resp"],
        data15a64_rn_ratio_its[which(data15a64_rn_ratio_its$year==2016),"hosp_resp"],
        data15a64_rn_ratio_its[which(data15a64_rn_ratio_its$year==2017),"hosp_resp"],
        data15a64_rn_ratio_its[which(data15a64_rn_ratio_its$year==2018),"hosp_resp"],
        data15a64_rn_ratio_its[which(data15a64_rn_ratio_its$year==2019),"hosp_resp"],
        data15a64_rn_ratio_its[which(data15a64_rn_ratio_its$year==2019),"did"],
        data15a64_rn_ratio_its[which(data15a64_rn_ratio_its$year==2019),"isoweek"]
        )
colnames(data15a64_rn_ratio_its_resp_hosp)<- c("hr_2015","hr_2016","hr_2017","hr_2018","hr_2019","did","isoweek")

data15a64_rn_ratio_its_trauma_cons<-
        cbind.data.frame(
        data15a64_rn_ratio_its[which(data15a64_rn_ratio_its$year==2015),"cons_trauma"],
        data15a64_rn_ratio_its[which(data15a64_rn_ratio_its$year==2016),"cons_trauma"],
        data15a64_rn_ratio_its[which(data15a64_rn_ratio_its$year==2017),"cons_trauma"],
        data15a64_rn_ratio_its[which(data15a64_rn_ratio_its$year==2018),"cons_trauma"],
        data15a64_rn_ratio_its[which(data15a64_rn_ratio_its$year==2019),"cons_trauma"],
        data15a64_rn_ratio_its[which(data15a64_rn_ratio_its$year==2019),"did"],
        data15a64_rn_ratio_its[which(data15a64_rn_ratio_its$year==2019),"isoweek"]
        )
colnames(data15a64_rn_ratio_its_trauma_cons)<- c("ct_2015","ct_2016","ct_2017","ct_2018","ct_2019","did","isoweek")

data15a64_rn_ratio_its_resp_cons<-
        cbind.data.frame(
        data15a64_rn_ratio_its[which(data15a64_rn_ratio_its$year==2015),"cons_resp"],
        data15a64_rn_ratio_its[which(data15a64_rn_ratio_its$year==2016),"cons_resp"],
        data15a64_rn_ratio_its[which(data15a64_rn_ratio_its$year==2017),"cons_resp"],
        data15a64_rn_ratio_its[which(data15a64_rn_ratio_its$year==2018),"cons_resp"],
        data15a64_rn_ratio_its[which(data15a64_rn_ratio_its$year==2019),"cons_resp"],
        data15a64_rn_ratio_its[which(data15a64_rn_ratio_its$year==2019),"did"],
        data15a64_rn_ratio_its[which(data15a64_rn_ratio_its$year==2019),"isoweek"]
        )
colnames(data15a64_rn_ratio_its_resp_cons)<- c("cr_2015","cr_2016","cr_2017","cr_2018","cr_2019","did","isoweek")

data15a64_rn_ratio_its_trauma_rate<-
        cbind.data.frame(
        data15a64_rn_ratio_its[which(data15a64_rn_ratio_its$year==2015),"rate"],
        data15a64_rn_ratio_its[which(data15a64_rn_ratio_its$year==2016),"rate"],
        data15a64_rn_ratio_its[which(data15a64_rn_ratio_its$year==2017),"rate"],
        data15a64_rn_ratio_its[which(data15a64_rn_ratio_its$year==2018),"rate"],
        data15a64_rn_ratio_its[which(data15a64_rn_ratio_its$year==2019),"rate"],
        data15a64_rn_ratio_its[which(data15a64_rn_ratio_its$year==2019),"did"],
        data15a64_rn_ratio_its[which(data15a64_rn_ratio_its$year==2019),"isoweek"]
        )
colnames(data15a64_rn_ratio_its_trauma_rate)<- c("rt_2015","rt_2016","rt_2017","rt_2018","rt_2019","did","isoweek")

data15a64_rn_ratio_its_resp_rate<-
        cbind.data.frame(
        data15a64_rn_ratio_its[which(data15a64_rn_ratio_its$year==2015),"rate_resp"],
        data15a64_rn_ratio_its[which(data15a64_rn_ratio_its$year==2016),"rate_resp"],
        data15a64_rn_ratio_its[which(data15a64_rn_ratio_its$year==2017),"rate_resp"],
        data15a64_rn_ratio_its[which(data15a64_rn_ratio_its$year==2018),"rate_resp"],
        data15a64_rn_ratio_its[which(data15a64_rn_ratio_its$year==2019),"rate_resp"],
        data15a64_rn_ratio_its[which(data15a64_rn_ratio_its$year==2019),"did"],
        data15a64_rn_ratio_its[which(data15a64_rn_ratio_its$year==2019),"isoweek"]
        )
colnames(data15a64_rn_ratio_its_resp_rate)<- c("rr_2015","rr_2016","rr_2017","rr_2018","rr_2019","did","isoweek")


rio::export(data15a64_rn_ratio_its,"data15a64_rn_ratio_its.dta")
```


```{r 10_did, messages=T, eval=F, warnings=T}

<br>

We generated several Fixed Effects Diff in Diff regressions to adjust for unobserved unit-specific (month) and confounders (circulatory) at the same time.

<br>
  
  <div style="border: 1px solid #ddd; padding: 5px; overflow-y: scroll; height:400px; overflow-x: scroll; width:100%">

####################################################
library(plm)


data_did<-cbind(
y=c("hosp_trauma", "hosp_resp", "cons_trauma","cons_resp","rate","rate_resp"),
x=c("hosp_circ", "hosp_circ", "cons_circ","cons_circ","rate_circ","rate_circ"),
colname=c("ht_","hr_","ct_","cr_","rt_","rr_")
)


rob_se_mr <-data.frame() 
for (i in  1:6) {
  assign(paste0(data_did[i,1],"_dummy_DiD_cov"), plm::plm(as.formula(paste0(data_did[i,1],"~ did+month+",data_did[i,2])), data=data15a64_rn_ratio_its, index=c("year", "isoweek"), model="within", effect= "individual"),#fixed effects ("within")
         envir = .GlobalEnv)
  #print(paste0(i,"_mr_dummy_DiD_cov"))
  #print(get(paste0(i,"_mr_dummy_DiD_cov")))
  rob_se_mr<- dplyr::bind_rows(rob_se_mr, sqrt(diag(vcovHC(get(paste0(data_did[i,1],"_dummy_DiD_cov")),  method = "arellano"))))
}
#https://stats.stackexchange.com/questions/66973/difference-between-fixed-effects-models-in-r-plm-and-stata-xtreg

#wald<- data.frame()
#for (i in 1:6) {
#  df_wald<- cbind(data_did[i,1],
##  plm::pwaldtest(get(paste0(data_did[i,1],"_dummy_DiD_cov")), vcov = function(x) vcovHC(x, type = "HC1"))$statistic,
#  plm::pwaldtest(get(paste0(data_did[i,1],"_dummy_DiD_cov")), vcov = function(x) vcovHC(x, type = "HC1"))$parameter)
#  wald<- rbind(wald,df_wald)
#}
  
#ls()[grep("*_MR_dummy_DiD_cov*",ls())]
AICs_BICs_fes<-
cbind.data.frame(
aicbic_plm(hosp_trauma_dummy_DiD_cov,"AIC"),
aicbic_plm(hosp_resp_dummy_DiD_cov,"AIC"),
aicbic_plm(cons_trauma_dummy_DiD_cov,"AIC"),
aicbic_plm(cons_resp_dummy_DiD_cov,"AIC"),
aicbic_plm(rate_dummy_DiD_cov,"AIC"),
aicbic_plm(rate_resp_dummy_DiD_cov,"AIC"),
aicbic_plm(hosp_trauma_dummy_DiD_cov,"BIC"),
aicbic_plm(hosp_resp_dummy_DiD_cov,"BIC"),
aicbic_plm(cons_trauma_dummy_DiD_cov,"BIC"),
aicbic_plm(cons_resp_dummy_DiD_cov,"BIC"),
aicbic_plm(rate_dummy_DiD_cov,"BIC"),
aicbic_plm(rate_resp_dummy_DiD_cov,"BIC")
)
#copy_names(melt(data.frame(AICs_BICs_fes)))

library(sandwich)

hcs_models<-data.frame()
for (i in 1:6) {
hcs<-t(sapply(c("HC0", "HC1", "HC2", "HC3", "HC4"), function(x) sqrt(diag(vcovHC(get(paste0(data_did[i,1],"_dummy_DiD_cov")), type = x))))) %>% data.table(keep.rownames = T) %>% slice_max(did1) %>% dplyr::select(rn)
hcs_models<-rbind(hcs_models,hcs)
}
#HC4 - small samples with influential observations HAC - heteroskedasticity and autocorrelation consistent (type ?vcovHAC for more details)
sjPlot::tab_model(
  list(hosp_trauma_dummy_DiD_cov,
                       hosp_resp_dummy_DiD_cov,
                       cons_trauma_dummy_DiD_cov,
                       cons_resp_dummy_DiD_cov,
                       rate_dummy_DiD_cov,
                       rate_resp_dummy_DiD_cov),
                  terms = c("did1"), 
                  vcov.fun = "HC",
                  string.est = "B",
                  collapse.ci = T,
                  robust= F,
                  digits= 2,
                  digits.p= 3,
                  show.aic = T,
                  ci.hyphen= ";",
                  p.style = "numeric_stars",
                  vcov.type = "HC4",
                  show.loglik= T,
                  show.p=T, 
                  show.df=F,
                  pred.labels= c("Social Protests"),
                  dv.labels= c("Trauma Hosp.","Respiratory Hosp.",
                                 "Trauma Cons.", "Respiratory Cons.",
                                 "Trauma Hosp. of Cons.","Respiratory Hosp. of Cons."), 
                  title="Estimated effect of the Social Protests, from fixed effects difference-in-difference models")

#qqnorm(residuals(hosp_resp_dummy_DiD_cov), ylab = 'Residuals')
#qqline(residuals(hosp_resp_dummy_DiD_cov))
#qqnorm(residuals(hosp_resp_dummy_DiD_cov), ylab = 'Residuals')
#qqline(residuals(hosp_resp_dummy_DiD_cov))

</div>

```

```{r 10_3_did_, messages=T, eval=F, warnings=T}
fixef(hosp_trauma_dummy_DiD_cov)
summary(fixef(hosp_trauma_dummy_DiD_cov))

fixefs <- merge(data15a64_rn_ratio_its, data.frame(year = names(fixef(hosp_trauma_dummy_DiD_cov)),
fixef = as.numeric(fixef(hosp_trauma_dummy_DiD_cov))),
all.x = TRUE, by = c("year"))[ , 6]

<br>

Nevertheless, must note that these coefficients are vulnerable to serial correlation. This is why difference-in-difference models were calculated in Stata, using the `xtscc` module. The code is accessible below.

<br>
```

<br>

Resulting data is available in the following  [link]("https://drive.google.com/uc?export=download&id=1_wamggiWaULbFbolokBlwmr2TZOSwubN") (https://drive.google.com/uc?export=download&id=1_wamggiWaULbFbolokBlwmr2TZOSwubN).

<br>

```{r 10_3_did_stata, messages=T, eval=F, echo=T, warnings=T}

```


```{stata, collectcode=TRUE}

cap ssc install outreg2c
cap install xtscc
cap ssc install coefplot
cap ssc install xttest3
cap ssc install xttest2
cap ssc install xtcsd

******************
clear all
******************
if _rc == 0 { 
	if `"`c(os)'"' == "Windows" & `"`c(username)'"' == "andre" global sf `"G:\Mi unidad\linkabbddyscriptderpaperestallidosocial"'
	cd `"${sf}"'
} 
else if _rc == 0 { 
	if `"`c(os)'"' == "Windows" & `"`c(username)'"' == "CISS Fondecyt" global sf `"G:\Mi unidad\Alvacast\CURES2_DB"'
	cd `"${sf}"'
	} 
	else if _rc == 0 { 
	if `"`c(os)'"' == "MacOSX" global sf `"/volumes/sdrive/data//"'
	cd `"${sf}"'
	}
	else if _rc == 0 { 
	mkdir "~\Stata_data" 
	} 
	else rmdir "~\Stata_data" 
 global sf `"~\Stata_data"' //if does not work
 *set working directory
 cd `"${sf}"'
 
	di `"${sf}"' 
	pwd

cap copy "https://github.com/FONDECYTACC/paperestallido/blob/main/data15a64_rn_ratio_its.dta?raw=true" data15a64_rn_ratio_its_did.dta,replace
use data15a64_rn_ratio_its_did.dta

xtset year isoweek

replace did=0 if year!=2019
replace did=0 if year==2019 & isoweek<43
generate byte didf=recode(did,0,1)
drop did
gen did= didf

*____________________________________________________________________________*
***GENERAR XTSCC FINAL
*____________________________________________________________________________*
*the value of consultation or hospitalizations on each value DID (including the omitted value), adjusted for the circulatory hospitalizatons/consultations/rate. 
*
*Because graphical evidence suggests
*a periodic behavior, the analysis includes the sin1 and cos1 variables, which are sine and cosine
*transformations of scaled time, respectively.

*add a fixed seasonality component based on the cosine of the season (month of year) scaled to the range (0, 2π) 
cap gen month_sin = sin(month*2*c(pi)/12)
cap gen month_cos = cos(month*2*c(pi)/12)//*(month*2*c(pi)



cap drop fe_*
cap drop xtscc_*
*local it `" "hosp_circ" "hosp_circ" "cons_circ" "cons_circ" "rate_circ" "rate_circ" "' 
local name `" "Trauma,Hospitalizations" "Respiratory,Hospitalizations" "Trauma,Consultations" "Respiratory,Consultations" "Trauma Hospitalizations,per Consultations (x1000)" "Respiratory Hospitalizations,per Consultations (x1000)" "' 
foreach v of varlist hosp_trauma hosp_resp ///
					 cons_trauma cons_resp ///
					 rate rate_resp {
    gettoken item it : it
	gettoken nam name : name
	xtscc  `v' i.tx##i.txtime, fe //*`item'
	estimates store xtscc_`v'_none
	margins, dydx(*) post 
	eststo xtscc_mar_`v'_n
	estimates restore xtscc_`v'_none
	predict fe_no_month_`v'
	xtscc  `v' i.tx##i.txtime c.month, fe //*`item'
	estimates store xtscc_`v'_cnt_mth
	margins i.tx##i.txtime, post
	eststo xtscc_mar_`v'_cnt_m
	estimates restore xtscc_`v'_cnt_mth
	predict fe_cont_month_`v'
	xtscc  `v' i.tx##i.txtime i.month, fe //*`item'
	estimates store xtscc_`v'_month
	margins i.tx##i.txtime, post
	eststo xtscc_mar_`v'_month
	estimates restore xtscc_`v'_month
	predict fe_month_`v' 
	eststo xtscc_mar_`v'_month
	xtscc  `v' i.tx##i.txtime c.month#c.month, fe  //*`item'
	estimates store xtscc_`v'_cd_mth
	margins i.tx##i.txtime, post
	eststo xtscc_mar_`v'_cd_m
	estimates restore xtscc_`v'_cd_mth
	predict fe_cuad_`v'
	xtscc  `v' i.tx##i.txtime month_cos month_sin, fe //*`item'
	estimates store xtscc_`v'_sincos
	margins i.tx##i.txtime, post
	eststo xtscc_mar_`v'_sc
	estimates restore xtscc_`v'_sincos
	predict fe_sin_cos_`v'
}

*matrix list r(table) ** para ver todos los términsos
*Another way to obtain results
cap erase fe_results.csv
esttab xtscc_* ///
using fe_results.csv, append wide varlabels(1.txtime "Social Protest") keep(1.txtime) nobaselevels  ///
	 stats(N N_clust r2, fmt(%9.0f %9.0f %4.3f)) ///
	 cells("b(star fmt(3) label(Coef)) ci_l(fmt(2) label(CI95_Lo)) ci_u(fmt(2) label(CI95_Up)) p(fmt(%7.3f) label(p-values))") ///
	 mtitles("Trauma Hospitalizations-None" "Trauma Hospitalizations-Continuous" "Trauma Hospitalizations-Factor" "Trauma Hospitalizations-Cuadratic" "Trauma Hospitalizations-SinCos" /// 
			"Respiratory Hospitalizations-None" "Respiratory Hospitalizations-Continuous" "Respiratory Hospitalizations-Factor" "Respiratory Hospitalizations-Cuadratic" "Respiratory Hospitalizations-SinCos" ///
			"Trauma Consultations-None" "Trauma Consultations-Continuous" "Trauma Consultations-Factor" "Trauma Consultations-Cuadratic" "Trauma Consultations-SinCos" ///
			"Respiratory Consultations-None" "Respiratory Consultations-Continuous" "Respiratory Consultations-Factor" "Respiratory Consultations-Cuadratic" "Respiratory Consultations-SinCos" ///
			"Trauma Hospitalizations per Trauma Consultations(x1000)-None" "Trauma Hospitalizations per Trauma Consultations(x1000)-Continuous" "Trauma Hospitalizations per Trauma Consultations(x1000)-Factor" "Trauma Hospitalizations per Trauma Consultations(x1000)-Cuadratic" "Trauma Hospitalizations per Trauma Consultations(x1000)-SinCos" ///
			"Respiratory Hospitalizations per Respiratory Consultations(x1000)-None" "Respiratory Hospitalizations per Respiratory Consultations(x1000)-Continuous" "Respiratory Hospitalizations per Respiratory Consultations(x1000)-Factor" "Respiratory Hospitalizations per Respiratory Consultations(x1000)-Cuadratic" "Respiratory Hospitalizations per Respiratory Consultations(x1000)-SinCos") ///
			legend label varwidth(25) ///
	 title(Panel Estimation: Driscoll-Kraay standard errors and controlling for Circulatory Hospitalizations Consultations or Rates) ///
	 compress
```


# Session Info

```{r save, echo=T, cache= T, paged.print=TRUE, warning=F,eval=T}
Sys.getenv("R_LIBS_USER")
rstudioapi::getSourceEditorContext()
      tryCatch(
                     {
      save.image(paste0(getwd(),"/","Definitive_models_2021.RData"))
      #rio::export(codebook_data, "C:/Users/andre/Dropbox/Covid-19_2020/Article_SecondManuscript/LT Environmental analysis/Databases/merged_data_post_ago.dta")
                     },
                         error = function(e){
      save.image(paste0(getwd(),"/","Definitive_models_2021.RData"))
      #rio::export(codebook_data, "C:/Users/CISS Fondecyt/Dropbox/Covid-19_2020/Article_SecondManuscript/LT Environmental analysis/Databases/merged_data_post_ago.dta")
                         }
                   )
sessionInfo()

#Use any number of times, to revert back to the last commit without deleting any files that you have recently created.
#git reset --soft HEAD~1
unlink('Causal_Impact2_hosp_resp_cache', recursive = TRUE)
unlink('Causal_Impact2_hosp_trauma_cache', recursive = TRUE)
unlink('Causal_Impact2_cons_resp_cache', recursive = TRUE)
unlink('Causal_Impact2_cons_trauma_cache', recursive = TRUE)
unlink('Causal_Impact2_cons_trauma_cache', recursive = TRUE)
unlink('Plots 2021-01-18_cache', recursive = TRUE)
unlink('BD_Compilation_cache', recursive = TRUE)
```