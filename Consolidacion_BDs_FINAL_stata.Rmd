---
title: "BSTS Selected Models"
author: "ags"
date: "2021-01-20"
output:
  html_document:
    code_folding: hide
    fig_height: 6
    fig_width: 8
    theme: spacelab
    toc: yes
    toc_depth: 6
    toc_float: yes
    number_sections: yes
---

```{=html}
<style type="text/css">
.tablelines table, .tablelines td, .tablelines th {
  border: 1px solid black;
  }
.centrado {
  text-align: center;
}
.table.center {
  margin-left:auto; 
  margin-right:auto;
}
.table_wrapper{
  display: block;
  overflow-x: auto;
  white-space: nowrap;
}
code.r{
  font-size: 8px;
}
body{ /* Normal  */
    text-align: justify;
}
.superbigimage{
  overflow-y:scroll;
  white-space: nowrap;
}
.superbigimage img{
  overflow-y: scroll;
  overflow-x: hidden;
}
p.comment {
  background-color: #FF7F79;
    padding: 10px;
  border: 1px solid black;
  margin-left: 25px;
  border-radius: 5px;
  font-style: italic;
}
</style>
```
```{=html}
<style>
  p.comment {
    background-color: #ff9a9a;
      padding: 10px;
    border: 1px solid red;
    margin-left: 25px;
    border-radius: 5px;
    font-style: italic;
  }

</style>
```
```{r setup0, include=T, message=F, warning=F}
rm(list=ls());gc()
unlink('Consolidacion_BDs_cache', recursive = TRUE)
unlink('Consolidacion_BDs_FINAL_cache', recursive = TRUE)
#load(url("https://drive.google.com/uc?export=download&id=1zLfLpJjGCfMSfwrtTnaOdBSgGg2ZCqjR"))
load(paste0(getwd(),"/","Procesos hasta 4_2.RData"))

#xaringan::inf_mr()

if(isTRUE(getOption('knitr.in.progress'))==T){
    clus_iter=30000
} else {
  input <- readline('¿Are you gonna run the dataset with the whole iterations? (Si/No): ')
  if(input=="Si"){
    clus_iter=30000
  } else {
    clus_iter=1000
  }
}
```

```{r setup, include=T, message=F, warning=F}
#arriba puse algunas opciones para que por defecto escondiera el código
#también cargue algunos estilo .css para que el texto me apareciera justificado, entre otras cosas.
local({r <- getOption("repos")
       r["CRAN"] <- "http://cran.r-project.org" 
       options(repos=r)
})

`%>%` <- magrittr::`%>%`
copy_names <- function(x,row.names=FALSE,col.names=TRUE,dec=",",...) {
  if(class(ungroup(x))[1]=="tbl_df"){
        if(options()$OutDec=="."){
            options(OutDec = dec)
            write.table(format(data.frame(x)),"clipboard",sep="\t",row.names=FALSE,col.names=col.names,...)
            options(OutDec = ".")
          return(x)
        } else {
            options(OutDec = ",")
            write.table(format(data.frame(x)),"clipboard",sep="\t",row.names=FALSE,col.names=col.names,...)
            options(OutDec = ",")
          return(x)    
        }
  } else {
        if(options()$OutDec=="."){
            options(OutDec = dec)
            write.table(format(x),"clipboard",sep="\t",row.names=FALSE,col.names=col.names,...)
            options(OutDec = ".")
          return(x)
        } else {
            options(OutDec = ",")
            write.table(format(x),"clipboard",sep="\t",row.names=FALSE,col.names=col.names,...)
            options(OutDec = ",")
          return(x)       
  }
 }
}  

unlink('Consolidacion_BDs_cache', recursive = TRUE)
if(!require(pacman)){install.packages("pacman")}

pacman::p_unlock(lib.loc = .libPaths()) #para no tener problemas reinstalando paquetes
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)
#dejo los paquetes estadísticos que voy a utilizar

if(!require(plotly)){install.packages("plotly")}
if(!require(lubridate)){install.packages("lubridate")}
if(!require(htmlwidgets)){install.packages("htmlwidgets")}
if(!require(tidyverse)){install.packages("tidyverse")}
if(!require(gganimate)){install.packages("gganimate")}
if(!require(readr)){install.packages("readr")}
if(!require(stringr)){install.packages("stringr")}
if(!require(data.table)){install.packages("data.table")}
if(!require(DT)){install.packages("DT")}
if(!require(ggplot2)){install.packages("ggplot2")}
if(!require(lattice)){install.packages("lattice")}
if(!require(forecast)){install.packages("forecast")}
if(!require(zoo)){install.packages("zoo")}
if(!require(panelView)){install.packages("panelView")}
if(!require(janitor)){install.packages("janitor")}
if(!require(rjson)){install.packages("rjson")}
if(!require(estimatr)){install.packages("estimatr")} 
if(!require(CausalImpact)){install.packages("CausalImpact")}
if(!require(textreg)){install.packages("textreg")}
if(!require(sjPlot)){install.packages("sjPlot")}
if(!require(foreign)){install.packages("foreign")}
if(!require(tsModel)){install.packages("tsModel")}
if(!require(lmtest)){install.packages("lmtest")}
if(!require(Epi)){install.packages("Epi")}
if(!require(splines)){install.packages("splines")}
if(!require(vcd)){install.packages("vcd")}
if(!require(astsa)){install.packages("astsa")}
if(!require(forecast)){install.packages("forecast")}
if(!require(MASS)){install.packages("MASS")}
if(!require(ggsci)){install.packages("ggsci")}
if(!require(Hmisc)){install.packages("Hmisc")}
if(!require(compareGroups)){install.packages("compareGroups")}
if(!require(dplyr)){install.packages("dplyr")}
if(!require(ggforce)){install.packages("ggforce")}
if(!require(imputeTS)){install.packages("imputeTS")}
if(!require(doParallel)){install.packages("doParallel")}
if(!require(SCtools)){install.packages("SCtools")}
if(!require(MSCMT)){install.packages("MSCMT")}
if(!require(ISOweek)){install.packages("ISOweek")}
if(!require(gridExtra)){install.packages("gridExtra")}
if(!require(cowplot)){install.packages("cowplot")}
if(!require(grid)){install.packages("grid")}
if(!require(devtools)){install.packages("devtools")}
if(!require(Statamarkdown)){devtools::install_github("hemken/Statamarkdown", quiet=T,  upgrade="never")}

# Calculate the number of cores
no_cores <- detectCores() - 1
cl<-makeCluster(no_cores)
registerDoParallel(cl)

Sys.setlocale(category = "LC_ALL", locale = "english")

#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:
#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:
#:#:#:#:#:#:#:#:#:#:#:PARA GENERAR MATRICES DE PREDICCION BSTS#:#:#:#:#:#:#:#:#:
#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:

GetPosteriorStateSamples <- function(bsts.model) {
  # Returns a matrix of simulated values from the marginal posterior
  # distribution for the sum of all state variables.
  #
  # Args:
  #   bsts.model: A fitted model returned by \code{bsts()}.
  #
  # Returns:
  #   matrix [number of post-burn-in MCMC samples] x [time points]
  
  # Get state contributions (e.g., 1000 samples x 2 states x 365 time pts),
  # discarding burn-in samples (=> 900 x 2 x 365)
  burn <- SuggestBurn(0.1, bsts.model)
  #assert_that(burn > 0)
  state.contributions <- bsts.model$state.contributions[-seq_len(burn), , ,
                                                        drop = FALSE]
  
  # Sum across states, call it 'state.samples' (=> 900 x 365)
  state.samples <- rowSums(aperm(state.contributions, c(1, 3, 2)), dims = 2)
  return(state.samples)
}
ComputeResponseTrajectories <- function(bsts.model) {
  # Generates trajectories of the response variable. A trajectory is a simulated
  # time series drawn from the posterior predictive distribution over the data.
  # This function differs from GetPosteriorStateSamples(). The latter returns
  # the posterior mean of the response. This function returns the actual value
  # (posterior mean + observation noise).
  #
  # Args:
  #   bsts.model: A model object as returned by \code{bsts()}.
  #
  # Returns:
  #   matrix [number of post-burn-in MCMC samples] x [time points]
  
  # Get posterior state samples
  state.samples <- GetPosteriorStateSamples(bsts.model)
  
  # Get observation noise standard deviation samples
  burn <- SuggestBurn(0.1, bsts.model)
  #assert_that(burn > 0)
  sigma.obs <- bsts.model$sigma.obs[-seq_len(burn)]  # e.g., 900
  
  # Sample from the posterior predictive density over data
  n.samples <- dim(state.samples)[1]  # e.g., 900 x 365
  obs.noise.samples <- matrix(rnorm(prod(dim(state.samples)), 0, sigma.obs),
                              nrow = n.samples)
  y.samples <- state.samples + obs.noise.samples
  return(y.samples)
}


#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:
#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:
aicbic_plm <- function(object, criterion) {
  
  
  # object is "plm", "panelmodel" 
  # Lets panel data has index :index = c("Country", "Time")
  
  sp = summary(object)
  
  if(class(object)[1]=="plm"){
    u.hat <- residuals(sp) # extract residuals
    df <- cbind(as.vector(u.hat), attr(u.hat, "index"))
    names(df) <- c("resid", "Country", "Time")
    c = length(levels(df$Country)) # extract country dimension 
    t = length(levels(df$Time)) # extract time dimension 
    np = length(sp$coefficients[,1]) # number of parameters
    n.N = nrow(sp$model) # number of data
    s.sq  <- log( (sum(u.hat^2)/(n.N))) # log sum of squares
    
    # effect = c("individual", "time", "twoways", "nested"),
    # model = c("within", "random", "ht", "between", "pooling", "fd")
    
    # I am making example only with some of the versions:
    
    if (sp$args$model == "within" & sp$args$effect == "individual"){
      n = c
      np = np+n+1 # update number of parameters
    }
    
    if (sp$args$model == "within" & sp$args$effect == "time"){
      T = t
      np = np+T+1 # update number of parameters
    }
    
    if (sp$args$model == "within" & sp$args$effect == "twoways"){
      n = c
      T = t
      np = np+n+T # update number of parameters
    }
    aic <- round(       2*np  +  n.N * (  log(2*pi) + s.sq  + 1 ),1)
    bic <- round(log(n.N)*np  +  n.N * (  log(2*pi) + s.sq  + 1 ),1)
    
    if(criterion=="AIC"){
      names(aic) = "AIC"
      return(aic)
    }
    if(criterion=="BIC"){
      names(bic) = "BIC"
      return(bic)
    }
  }
}
```


```{stata, collectcode=TRUE}
clear all 

cap ssc install outreg2c
cap install xtscc
cap ssc install coefplot
cap ssc install xttest3
cap ssc install xttest2
cap ssc install xtcsd
cap ssc install estout

******************
******************

cap copy "https://github.com/FONDECYTACC/paperestallido/blob/main/data15a64_rn_ratio_its.dta?raw=true" data15a64_rn_ratio_its_did.dta,replace
use data15a64_rn_ratio_its_did.dta

xtset year isoweek

replace did=0 if year!=2019
replace did=0 if year==2019 & isoweek<43
generate byte didf=recode(did,0,1)
drop did
gen did= didf

*____________________________________________________________________________*
***GENERAR XTSCC FINAL
*____________________________________________________________________________*
*the value of consultation or hospitalizations on each value DID (including the omitted value), adjusted for the circulatory hospitalizatons/consultations/rate. 
*

cap drop fe_*
cap drop xtscc_*
cap drop mar_xtscc_*

*local it `" "hosp_circ" "hosp_circ" "cons_circ" "cons_circ" "rate_circ" "rate_circ" "' 
local name `" "Trauma,Hospitalizations" "Respiratory,Hospitalizations" "Trauma,Consultations" "Respiratory,Consultations" "Trauma Hospitalizations,per Consultations (x1000)" "Respiratory Hospitalizations,per Consultations (x1000)" "' 
foreach v of varlist hosp_trauma hosp_resp ///
                     cons_trauma cons_resp ///
                     rate rate_resp {
    gettoken item it : it
    gettoken nam name : name
    qui xtscc  `v' i.tx##i.txtime, fe 
    estimates store xtscc_`v'_n
    qui margins i.tx##i.txtime, post
    eststo mar_xtscc_`v'_n
    estimates restore xtscc_`v'_n
    predict fe_no_month_`v'
    qui xtscc  `v' i.tx##i.txtime c.month, fe 
    estimates store xtscc_`v'_ct_m
    qui margins i.tx##i.txtime, post
    eststo mar_xtscc_`v'_ct_m
    estimates restore xtscc_`v'_ct_m
    predict fe_cont_month_`v'
    qui xtscc  `v' i.tx##i.txtime i.month, fe 
    estimates store xtscc_`v'_mth
    qui margins i.tx##i.txtime, post
    eststo mar_xtscc_`v'_mth
    estimates restore xtscc_`v'_mth
    predict fe_month_`v' 
    eststo mar_xtscc_`v'_mth
    qui xtscc  `v' i.tx##i.txtime c.month#c.month, fe  
    estimates store xtscc_`v'_cd_m
    qui margins i.tx##i.txtime, post
    eststo mar_xtscc_`v'_cd_m
    estimates restore xtscc_`v'_cd_m
    predict fe_cuad_`v'
    qui xtscc  `v' i.tx##i.txtime month_cos month_sin, fe 
    estimates store xtscc_`v'_sc
    qui margins i.tx##i.txtime, post
    eststo mar_xtscc_`v'_sc
    estimates restore xtscc_`v'_sc
    predict fe_sin_cos_`v'
}

*matrix list r(table) ** para ver todos los términsos
*Another way to obtain results
cap erase fe_results.csv
esttab xtscc_* ///
using fe_results.csv, append varlabels(1.txtime "Social Protest") keep(1.txtime) nobaselevels  ///
     stats(N N_clust r2, fmt(%9.0f %9.0f %4.3f)) ///
     cells("b(star fmt(3) label(Coef)) ci_l(fmt(2) label(CI95_Lo)) ci_u(fmt(2) label(CI95_Up)) p(fmt(%7.3f) label(p-values))") ///
     mtitles("Trauma Hospitalizations-None" "Trauma Hospitalizations-Continuous" "Trauma Hospitalizations-Factor" "Trauma Hospitalizations-Cuadratic" "Trauma Hospitalizations-SinCos" /// 
            "Respiratory Hospitalizations-None" "Respiratory Hospitalizations-Continuous" "Respiratory Hospitalizations-Factor" "Respiratory Hospitalizations-Cuadratic" "Respiratory Hospitalizations-SinCos" ///
            "Trauma Consultations-None" "Trauma Consultations-Continuous" "Trauma Consultations-Factor" "Trauma Consultations-Cuadratic" "Trauma Consultations-SinCos" ///
            "Respiratory Consultations-None" "Respiratory Consultations-Continuous" "Respiratory Consultations-Factor" "Respiratory Consultations-Cuadratic" "Respiratory Consultations-SinCos" ///
            "Trauma Hospitalizations per Trauma Consultations(x1000)-None" "Trauma Hospitalizations per Trauma Consultations(x1000)-Continuous" "Trauma Hospitalizations per Trauma Consultations(x1000)-Factor" "Trauma Hospitalizations per Trauma Consultations(x1000)-Cuadratic" "Trauma Hospitalizations per Trauma Consultations(x1000)-SinCos" ///
            "Respiratory Hospitalizations per Respiratory Consultations(x1000)-None" "Respiratory Hospitalizations per Respiratory Consultations(x1000)-Continuous" "Respiratory Hospitalizations per Respiratory Consultations(x1000)-Factor" "Respiratory Hospitalizations per Respiratory Consultations(x1000)-Cuadratic" "Respiratory Hospitalizations per Respiratory Consultations(x1000)-SinCos") ///
            legend label varwidth(25) ///
     title(Panel Estimation: Driscoll-Kraay standard errors) ///
     compress
	 
*******************************************************************************
**** XTREG LET ME ESTIMATE AIC & BIC, SHOULD NOT DIFFER WITH XTSCC
*******************************************************************************


local name `" "Trauma,Hospitalizations" "Respiratory,Hospitalizations" "Trauma,Consultations" "Respiratory,Consultations" "Trauma Hospitalizations,per Consultations (x1000)" "Respiratory Hospitalizations,per Consultations (x1000)" "' 
foreach v of varlist hosp_trauma hosp_resp ///
					 cons_trauma cons_resp ///
					 rate rate_resp {
	gettoken item it : it
	gettoken nam name : name
	qui xtreg `v' i.tx##i.txtime, fe 
	estimates store xtreg_`v'_none
	qui xtreg `v' i.tx##i.txtime c.month, fe 
	estimates store xtreg_`v'_cont				 
	qui xtreg `v' i.tx##i.txtime i.month, fe 
	estimates store xtreg_`v'_fact
	qui xtreg `v' i.tx##i.txtime c.month#c.month, fe 
	estimates store xtreg_`v'_cuad
	qui xtreg `v' i.tx##i.txtime month_sin month_cos, fe 
	estimates store xtreg_`v'_sin_cos
}
*****************************************v**************************************
*****************************************v**************************************
***********TABLES************************v**************************************

qui est table xtreg_hosp_trauma_*, star b(%7.4f) stats(N r2_a aic bic rmse) keep(1.txtime)
qui return list
matrix stats_a = r(stats)'
matrix rownames stats_a = "TH-None" "TH-Cont" "TH-Fact" "TH-Cuad" "TH-SinCos"
svmat stats_a 
qui est table xtreg_hosp_resp_*, star b(%7.4f) stats(N r2_a aic bic rmse) keep(1.txtime)
qui return list
matrix stats_b = r(stats)'
matrix rownames stats_b = "RH-None" "RH-Cont" "RH-Fact" "RH-Cuad" "RH-SinCos"
svmat stats_b
qui est table xtreg_cons_trauma_*, star b(%7.4f) stats(N r2_a aic bic rmse) keep(1.txtime)
qui return list
matrix stats_c = r(stats)'
matrix rownames stats_c = "TC-None" "TC-Cont" "TC-Fact" "TC-Cuad" "TC-SinCos"
svmat stats_c
qui est table xtreg_cons_resp_*, star b(%7.4f) stats(N r2_a aic bic rmse) keep(1.txtime)
qui return list
matrix stats_d = r(stats)'
matrix rownames stats_d = "RC-None" "RC-Cont" "RC-Fact" "RC-Cuad" "RC-SinCos"
svmat stats_d
qui est table xtreg_rate_none xtreg_rate_cont xtreg_rate_fact xtreg_rate_cuad xtreg_rate_sin_cos, star b(%7.4f) stats(N r2_a aic bic rmse) keep(1.txtime)
qui return list
matrix stats_e = r(stats)'
matrix rownames stats_e = "TR-None" "TR-Cont" "TR-Fact" "TR-Cuad" "TR-SinCos"
svmat stats_e
qui est table xtreg_rate_resp_*, star b(%7.4f) stats(N r2_a aic bic rmse) keep(1.txtime)
qui return list
matrix stats_f = r(stats)'
matrix rownames stats_f = "RR-None" "RR-Cont" "RR-Fact" "RR-Cuad" "RR-SinCos"
svmat stats_f 

matrix comb = (stats_a \ stats_b \ stats_c \ stats_d \ stats_e \ stats_f)

cap erase using fe_results_fit.csv
esttab matrix(comb) ///
using fe_results_fit.csv

*****************************************v**************************************
*****************************************v**************************************
*****************************************v**************************************
* TH-SinCos  RH-Fact  TC-Fact RC-SinCos  TR-Fact RR-Fact


*if((r(table)[1,4]/r(table)[1,9])<1) {
*	local: di %9.2f (1-(r(table)[1,4]/r(table)[1,9]))*100
*	}
*else if((r(table)[1,4]/r(table)[1,9])>1){
*	di %9.2f ((r(table)[1,4]/r(table)[1,9])-1)*100
*	}

* TH-SinCos 
qui xtscc  hosp_trauma i.tx##i.txtime month_cos month_sin, fe 
qui margins,eydx(txtime) atmeans

scalar beti_TH_SinCos = r(table)[1,2]*100
scalar beti_TH_SinCos = round(`=scalar(beti_TH_SinCos)', .01)
scalar CI95_lo_TH_SinCos = r(table)[5,2]*100
scalar CI95_lo_TH_SinCos = round(`=scalar(CI95_lo_TH_SinCos)', .01)
scalar CI95_up_TH_SinCos = r(table)[6,2]*100
scalar CI95_up_TH_SinCos = round(`=scalar(CI95_up_TH_SinCos)', .01)

*  RH_Fact
qui xtscc  hosp_resp i.tx##i.txtime i.month, fe 
qui margins,eydx(txtime) atmeans

scalar beti_RH_Fact = r(table)[1,2]*100
scalar beti_RH_Fact = round(`=scalar(beti_RH_Fact)', .01)
scalar CI95_lo_RH_Fact = r(table)[5,2]*100
scalar CI95_lo_RH_Fact = round(`=scalar(CI95_lo_RH_Fact)', .01)
scalar CI95_up_RH_Fact = r(table)[6,2]*100
scalar CI95_up_RH_Fact = round(`=scalar(CI95_up_RH_Fact)', .01)

* TC_Fact
qui xtscc  cons_trauma i.tx##i.txtime i.month, fe 
qui margins,eydx(txtime) atmeans

scalar beti_TC_Fact = r(table)[1,2]*100
scalar beti_TC_Fact = round(`=scalar(beti_TC_Fact)', .01)
scalar CI95_lo_TC_Fact = r(table)[5,2]*100
scalar CI95_lo_TC_Fact = round(`=scalar(CI95_lo_TC_Fact)', .01)
scalar CI95_up_TC_Fact = r(table)[6,2]*100
scalar CI95_up_TC_Fact = round(`=scalar(CI95_up_TC_Fact)', .01)

* RC_SinCos
qui xtscc  cons_resp i.tx##i.txtime month_cos month_sin, fe 
qui margins,eydx(txtime) atmeans

scalar beti_RC_SinCos = r(table)[1,2]*100
scalar beti_RC_SinCos = round(`=scalar(beti_RC_SinCos)', .01)
scalar CI95_lo_RC_SinCos = r(table)[5,2]*100
scalar CI95_lo_RC_SinCos = round(`=scalar(CI95_lo_RC_SinCos)', .01)
scalar CI95_up_RC_SinCos = r(table)[6,2]*100
scalar CI95_up_RC_SinCos = round(`=scalar(CI95_up_RC_SinCos)', .01)

* TR_Fact
qui xtscc  rate i.tx##i.txtime i.month, fe 
qui margins,eydx(txtime) atmeans

scalar beti_TR_Fact = r(table)[1,2]*100
scalar beti_TR_Fact = round(`=scalar(beti_TR_Fact)', .01)
scalar CI95_lo_TR_Fact = r(table)[5,2]*100
scalar CI95_lo_TR_Fact = round(`=scalar(CI95_lo_TR_Fact)', .01)
scalar CI95_up_TR_Fact = r(table)[6,2]*100
scalar CI95_up_TR_Fact = round(`=scalar(CI95_up_TR_Fact)', .01)

* RR_Fact
qui xtscc  rate_resp i.tx##i.txtime i.month, fe 
qui margins,eydx(txtime) atmeans

scalar beti_RR_Fact = r(table)[1,2]*100
scalar beti_RR_Fact = round(`=scalar(beti_RR_Fact)', .01)
scalar CI95_lo_RR_Fact = r(table)[5,2]*100
scalar CI95_lo_RR_Fact = round(`=scalar(CI95_lo_RR_Fact)', .01)
scalar CI95_up_RR_Fact = r(table)[6,2]*100
scalar CI95_up_RR_Fact = round(`=scalar(CI95_up_RR_Fact)', .01)

cap erase fe_results_selection.csv
*# https://www.statalist.org/forums/forum/general-stata-discussion/general/1437172-margins-and-diff-in-diff-estimates
*# https://stats.stackexchange.com/questions/482869/differences-between-calculating-the-relative-change-and-taking-the-natural-log-t
esttab xtscc_hosp_trauma_sc  xtscc_hosp_resp_mth  ///
xtscc_cons_trauma_mth  xtscc_cons_resp_sc xtscc_rate_mth xtscc_rate_resp_mth ///
using fe_results_selection.csv, ///
append varlabels(1.txtime "Social Protest") keep(1.txtime) nobaselevels  ///
     stats(N r2_w, fmt(%9.0f %4.2f)) ///
     cells(b(fmt(2) label(Coef)) ci_l(fmt(2) label(CI95_Lo)) ci_u(fmt(2) label(CI95_Up)) p(fmt(%7.3f) label(p-values))) ///
	 mtitles("Trauma Hospitalizations-SinCos" "Respiratory Hospitalizations-Factor" "Trauma Consultations-Factor" "Respiratory Consultations-SinCos" ///
             "Trauma Hospitalizations per Trauma Consultations(x1000)-Factor" ///
             "Respiratory Hospitalizations per Respiratory Consultations(x1000)-Factor") ///	 
     legend label ///
     title(Panel Estimation: Driscoll-Kraay standard errors) ///
     compress nogap 

esttab xtscc_hosp_trauma_sc  xtscc_hosp_resp_mth  ///
xtscc_cons_trauma_mth  xtscc_cons_resp_sc xtscc_rate_mth xtscc_rate_resp_mth, ///
varlabels(1.txtime "Social Protest") keep(1.txtime) nobaselevels  ///
     stats(N r2_w, fmt(%9.0f %4.2f)) ///
     cells(b(fmt(2) label(Coef)) ci_l(fmt(2) label(CI95_Lo)) ci_u(fmt(2) label(CI95_Up)) p(fmt(%7.3f) label(p-values))) ///
     mtitles("TH-SinCos" "RH-Factor" "TC-Factor" "RC-SinCos" ///
             "TR-Factor" ///
             "RR-Factor") ///     
     legend label ///
     title(Panel Estimation: Driscoll-Kraay standard errors) ///
     compress nogap
	 
	 
*#:#:#:#:#:#:##:#:#:#:#:#:#:#:#:#:#:#:#:##:#:#:#:#:#:#:#:#:#:#:#:#:##:#:#:#:#:#:#:
*#:#:#:#:#:#:##:#:#:#:#:#:#:#:#:#:#:#:#:##:#:#:#:#:#:#:#:#:#:#:#:#:##:#:#:#:#:#:#:
*#:#:#:#:#:#:##:#:#:#:#:#:#:#:#:#:#:#:#:##:#:#:#:#:#:#:#:#:#:#:#:#:##:#:#:#:#:#:#:	 
** Relative differences:

log using log.txt, replace text
di "`=scalar(beti_TH_SinCos)' [`=scalar(CI95_lo_TH_SinCos)',`=scalar(CI95_up_TH_SinCos)']" 
di "`=scalar(beti_RH_Fact)' [`=scalar(CI95_lo_RH_Fact)',`=scalar(CI95_up_RH_Fact)']" 
di "`=scalar(beti_TC_Fact)' [`=scalar(CI95_lo_TC_Fact)',`=scalar(CI95_up_TC_Fact)']" 
di "`=scalar(beti_RC_SinCos)' [`=scalar(CI95_lo_RC_SinCos)',`=scalar(CI95_up_RC_SinCos)']" 
di "`=scalar(beti_TR_Fact)' [`=scalar(CI95_lo_TR_Fact)',`=scalar(CI95_up_TR_Fact)']" 
di "`=scalar(beti_RR_Fact)' [`=scalar(CI95_lo_RR_Fact)',`=scalar(CI95_up_RR_Fact)']" 
log close 
```


```{r 10_3_did_eeee, messages=T, eval=F, warnings=T}
fe_results_selection <- readr::read_csv("fe_results_selection.csv")
#fe_results_selection <- readr::read_delim("log.txt")

```

# Session Info

```{r save, echo=T, cache= T, paged.print=TRUE, warning=F,eval=F}
Sys.getenv("R_LIBS_USER")
rstudioapi::getSourceEditorContext()
      tryCatch(
                     {
      #rio::export(codebook_data, "C:/Users/andre/Dropbox/Covid-19_2020/Article_SecondManuscript/LT Environmental analysis/Databases/merged_data_post_ago.dta")
                     },
                         error = function(e){
      save.image(paste0(getwd(),"/","Definitive_models_2021.RData"))
      #rio::export(codebook_data, "C:/Users/CISS Fondecyt/Dropbox/Covid-19_2020/Article_SecondManuscript/LT Environmental analysis/Databases/merged_data_post_ago.dta")
                         }
                   )
sessionInfo()
```